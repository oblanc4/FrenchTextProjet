{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>lexical_complexite</th>\n",
       "      <th>note_orthographe</th>\n",
       "      <th>char_length</th>\n",
       "      <th>word_length</th>\n",
       "      <th>type_token_ratio</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>complexite_texte</th>\n",
       "      <th>...</th>\n",
       "      <th>DET</th>\n",
       "      <th>PRON</th>\n",
       "      <th>NUM</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>VERB</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>SCONJ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Les coûts kilométriques réels peuvent diverger...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.194007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.160077</td>\n",
       "      <td>0.140152</td>\n",
       "      <td>0.467105</td>\n",
       "      <td>0.140152</td>\n",
       "      <td>0.339713</td>\n",
       "      <td>0.244565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Le bleu, c'est ma couleur préférée mais je n'a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.082334</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.036990</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Le test de niveau en français est sur le site ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.088078</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.039541</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.195804</td>\n",
       "      <td>0.081522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Est-ce que ton mari est aussi de Boston?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.062664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022959</td>\n",
       "      <td>0.026515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026515</td>\n",
       "      <td>0.193182</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dans les écoles de commerce, dans les couloirs...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.184993</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.130740</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.602941</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.288770</td>\n",
       "      <td>0.228261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  difficulty  \\\n",
       "id                                                                  \n",
       "0   Les coûts kilométriques réels peuvent diverger...           4   \n",
       "1   Le bleu, c'est ma couleur préférée mais je n'a...           0   \n",
       "2   Le test de niveau en français est sur le site ...           0   \n",
       "3            Est-ce que ton mari est aussi de Boston?           0   \n",
       "4   Dans les écoles de commerce, dans les couloirs...           2   \n",
       "\n",
       "    lexical_complexite  note_orthographe  char_length  word_length  \\\n",
       "id                                                                   \n",
       "0             0.194007          1.000000     0.160077     0.140152   \n",
       "1             0.082334          1.000000     0.036990     0.041667   \n",
       "2             0.088078          0.769231     0.039541     0.045455   \n",
       "3             0.062664          1.000000     0.022959     0.026515   \n",
       "4             0.184993          1.000000     0.130740     0.125000   \n",
       "\n",
       "    type_token_ratio  sentence_length  avg_word_length  complexite_texte  ...  \\\n",
       "id                                                                        ...   \n",
       "0           0.467105         0.140152         0.339713          0.244565  ...   \n",
       "1           1.000000         0.041667         0.204545          0.086957  ...   \n",
       "2           0.826923         0.045455         0.195804          0.081522  ...   \n",
       "3           1.000000         0.026515         0.193182          0.054348  ...   \n",
       "4           0.602941         0.125000         0.288770          0.228261  ...   \n",
       "\n",
       "         DET      PRON       NUM      NOUN  INTJ       ADP       ADJ  \\\n",
       "id                                                                     \n",
       "0   0.066667  0.000000  0.000000  0.311111   0.0  0.288889  0.066667   \n",
       "1   0.187500  0.125000  0.000000  0.125000   0.0  0.000000  0.000000   \n",
       "2   0.200000  0.000000  0.000000  0.400000   0.0  0.266667  0.000000   \n",
       "3   0.000000  0.100000  0.000000  0.300000   0.0  0.100000  0.000000   \n",
       "4   0.095238  0.047619  0.047619  0.238095   0.0  0.261905  0.047619   \n",
       "\n",
       "        VERB   PROPN  SCONJ  \n",
       "id                           \n",
       "0   0.088889  0.0000    0.0  \n",
       "1   0.125000  0.0625    0.0  \n",
       "2   0.066667  0.0000    0.0  \n",
       "3   0.100000  0.1000    0.1  \n",
       "4   0.095238  0.0000    0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "training_data = pd.read_csv(\"data/training_dataPhil.csv\", index_col=0)\n",
    "\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modèle pré-entraîné Sentence-CamemBERT-Large en français"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362243cb487e4038a772e84d7cc725ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading .gitattributes:   0%|          | 0.00/1.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec217d41bbcb4c26975a3365c6944806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading README.md:   0%|          | 0.00/5.25k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a86088d7de0c491a8520173bd44f55af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/683 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d565233e5c6453bb97d9ed471ee6729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/1.35G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f89f3c3d7a94250ba1ad01c8ae51cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.35G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf79c91d60c342498b05cf714eb76bb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/27.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47bd535ea1e9498e877d822f9ba26334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/809k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34db5ddd66584d8cab2f9dc703988918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/298 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a2c96dc6cc4c939c0efdabfd867679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/400 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /Users/phil/.cache/torch/sentence_transformers/dangvantuan_sentence-camembert-large. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Charger le modèle Sentence CamemBERT\n",
    "model_name = \"dangvantuan/sentence-camembert-large\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# Supposons que training_data contient vos données avec les phrases\n",
    "phrases = training_data['sentence'].tolist()\n",
    "\n",
    "# Générer des embeddings pour chaque phrase\n",
    "bert_embeddings = model.encode(phrases)\n",
    "\n",
    "# Les embeddings sont maintenant stockés dans la variable 'embeddings'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divison des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "training_data_x = training_data.drop(columns=[\"difficulty\", \"sentence\"])\n",
    "X_combined = np.concatenate((bert_embeddings, training_data_x), axis=1)\n",
    "\n",
    "X = X_combined  # Les embeddings réduits après PCA\n",
    "y = training_data[\"difficulty\"]  # Les niveaux de difficulté (étiquettes)\n",
    "\n",
    "# Effectuez la division en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Régression Logistique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle de régression logistique : 0.4947916666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Créez un modèle de régression logistique\n",
    "logistic_regression_model = LogisticRegression()\n",
    "\n",
    "# Entraînez le modèle sur l'ensemble d'entraînement\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# Évaluez la performance du modèle sur l'ensemble de test\n",
    "accuracy = logistic_regression_model.score(X_test, y_test)\n",
    "print(\"Précision du modèle de régression logistique :\", accuracy)\n",
    "\n",
    "del logistic_regression_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM (Support Vector Machine) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle SVM : 0.5427083333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Créez un modèle SVM (classification)\n",
    "svm_model = SVC()\n",
    "\n",
    "# Entraînez le modèle sur l'ensemble d'entraînement\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Évaluez la performance du modèle sur l'ensemble de test\n",
    "accuracy = svm_model.score(X_test, y_test)\n",
    "print(\"Précision du modèle SVM :\", accuracy)\n",
    "\n",
    "del svm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arbres de Décision :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle d'arbre de décision : 0.33541666666666664\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Créez un modèle d'arbre de décision\n",
    "decision_tree_model = DecisionTreeClassifier()\n",
    "\n",
    "# Entraînez le modèle sur l'ensemble d'entraînement\n",
    "decision_tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Évaluez la performance du modèle sur l'ensemble de test\n",
    "accuracy = decision_tree_model.score(X_test, y_test)\n",
    "print(\"Précision du modèle d'arbre de décision :\", accuracy)\n",
    "\n",
    "del decision_tree_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forêts Aléatoires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle de forêt aléatoire : 0.475\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Créez un modèle de forêt aléatoire\n",
    "random_forest_model = RandomForestClassifier()\n",
    "\n",
    "# Entraînez le modèle sur l'ensemble d'entraînement\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Évaluez la performance du modèle sur l'ensemble de test\n",
    "accuracy = random_forest_model.score(X_test, y_test)\n",
    "print(\"Précision du modèle de forêt aléatoire :\", accuracy)\n",
    "\n",
    "del random_forest_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réseaux de Neurones (utilisant scikit-learn) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle de réseau de neurones : 0.5177083333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Créez un modèle de réseau de neurones (multilayer perceptron)\n",
    "mlp_model = MLPClassifier()\n",
    "\n",
    "# Entraînez le modèle sur l'ensemble d'entraînement\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "# Évaluez la performance du modèle sur l'ensemble de test\n",
    "accuracy = mlp_model.score(X_test, y_test)\n",
    "print(\"Précision du modèle de réseau de neurones :\", accuracy)\n",
    "\n",
    "del mlp_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réseaux de Neurones Récursifs - RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66       166\n",
      "           1       0.45      0.47      0.46       158\n",
      "           2       0.41      0.37      0.39       166\n",
      "           3       0.49      0.49      0.49       153\n",
      "           4       0.48      0.46      0.47       152\n",
      "           5       0.63      0.63      0.63       165\n",
      "\n",
      "    accuracy                           0.52       960\n",
      "   macro avg       0.52      0.52      0.52       960\n",
      "weighted avg       0.52      0.52      0.52       960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Créez votre modèle de classification (par exemple, Réseaux de Neurones Récursifs - RNN)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "rnn_model = MLPClassifier(hidden_layer_sizes=(100,), activation='tanh', solver='adam', max_iter=1000, random_state=42)\n",
    "\n",
    "# Entraînez le modèle sur l'ensemble d'entraînement\n",
    "rnn_model.fit(X_train, y_train)\n",
    "\n",
    "# Prédisez les niveaux de difficulté sur l'ensemble de test\n",
    "y_pred_rnn = rnn_model.predict(X_test)\n",
    "\n",
    "# Évaluez la performance du modèle\n",
    "accuracy_rnn = rnn_model.score(X_test, y_pred_rnn)\n",
    "print(classification_report(y_test, y_pred_rnn))\n",
    "\n",
    "del rnn_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
