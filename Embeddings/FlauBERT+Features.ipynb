{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We employ FlauBERT to enhance the performance of our natural language processing task. To further boost the model's proficiency, we augment our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>note_orthographe</th>\n",
       "      <th>lexical_complexite</th>\n",
       "      <th>char_length</th>\n",
       "      <th>word_length</th>\n",
       "      <th>type_token_ratio</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>complexite_texte</th>\n",
       "      <th>...</th>\n",
       "      <th>DET</th>\n",
       "      <th>PRON</th>\n",
       "      <th>NUM</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>VERB</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>SCONJ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Les coûts kilométriques réels peuvent diverger...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194007</td>\n",
       "      <td>0.160077</td>\n",
       "      <td>0.140152</td>\n",
       "      <td>0.467105</td>\n",
       "      <td>0.140152</td>\n",
       "      <td>0.339713</td>\n",
       "      <td>0.244565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Le bleu, c'est ma couleur préférée mais je n'a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.082334</td>\n",
       "      <td>0.036990</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Le test de niveau en français est sur le site ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.088078</td>\n",
       "      <td>0.039541</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.195804</td>\n",
       "      <td>0.081522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Est-ce que ton mari est aussi de Boston?</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062664</td>\n",
       "      <td>0.022959</td>\n",
       "      <td>0.026515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026515</td>\n",
       "      <td>0.193182</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dans les écoles de commerce, dans les couloirs...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.184993</td>\n",
       "      <td>0.130740</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.602941</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.288770</td>\n",
       "      <td>0.228261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  difficulty  \\\n",
       "id                                                                  \n",
       "0   Les coûts kilométriques réels peuvent diverger...           4   \n",
       "1   Le bleu, c'est ma couleur préférée mais je n'a...           0   \n",
       "2   Le test de niveau en français est sur le site ...           0   \n",
       "3            Est-ce que ton mari est aussi de Boston?           0   \n",
       "4   Dans les écoles de commerce, dans les couloirs...           2   \n",
       "\n",
       "    note_orthographe  lexical_complexite  char_length  word_length  \\\n",
       "id                                                                   \n",
       "0           1.000000            0.194007     0.160077     0.140152   \n",
       "1           1.000000            0.082334     0.036990     0.041667   \n",
       "2           0.769231            0.088078     0.039541     0.045455   \n",
       "3           1.000000            0.062664     0.022959     0.026515   \n",
       "4           1.000000            0.184993     0.130740     0.125000   \n",
       "\n",
       "    type_token_ratio  sentence_length  avg_word_length  complexite_texte  ...  \\\n",
       "id                                                                        ...   \n",
       "0           0.467105         0.140152         0.339713          0.244565  ...   \n",
       "1           1.000000         0.041667         0.204545          0.086957  ...   \n",
       "2           0.826923         0.045455         0.195804          0.081522  ...   \n",
       "3           1.000000         0.026515         0.193182          0.054348  ...   \n",
       "4           0.602941         0.125000         0.288770          0.228261  ...   \n",
       "\n",
       "         DET      PRON       NUM      NOUN  INTJ       ADP       ADJ  \\\n",
       "id                                                                     \n",
       "0   0.066667  0.000000  0.000000  0.311111   0.0  0.288889  0.066667   \n",
       "1   0.187500  0.125000  0.000000  0.125000   0.0  0.000000  0.000000   \n",
       "2   0.200000  0.000000  0.000000  0.400000   0.0  0.266667  0.000000   \n",
       "3   0.000000  0.100000  0.000000  0.300000   0.0  0.100000  0.000000   \n",
       "4   0.095238  0.047619  0.047619  0.238095   0.0  0.261905  0.047619   \n",
       "\n",
       "        VERB   PROPN  SCONJ  \n",
       "id                           \n",
       "0   0.088889  0.0000    0.0  \n",
       "1   0.125000  0.0625    0.0  \n",
       "2   0.066667  0.0000    0.0  \n",
       "3   0.100000  0.1000    0.1  \n",
       "4   0.095238  0.0000    0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "training_data = pd.read_csv(\"../Dataset_upgrade/training_dataUP.csv\", index_col=0)\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pre-trained model FlauBERT base in french**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# pre-trained model\n",
    "model_name = \"flaubert/flaubert_base_cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "phrases = training_data['sentence'].tolist()\n",
    "\n",
    "# Use the tokenizer to convert phrases into FlauBERT tokens\n",
    "tokenized_phrases = tokenizer(phrases, padding=True, truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "\n",
    "with torch.no_grad():\n",
    "    embeddings = model(**tokenized_phrases)\n",
    "\n",
    "bert_embeddings = embeddings.last_hidden_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PCA gives us the best results compared to t-SNE or UMAP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "num_examples, seq_length, embedding_dim = bert_embeddings.shape\n",
    "bert_embeddings_2d = bert_embeddings.reshape(num_examples, -1) \n",
    "\n",
    "# Apply PCA to two-dimensional embeddings\n",
    "num_components = 50\n",
    "pca = PCA(n_components=num_components)\n",
    "reduced_embeddings = pca.fit_transform(bert_embeddings_2d)\n",
    "del pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "training_data_x = training_data.drop(columns=[\"difficulty\", \"sentence\"])\n",
    "X_combined = np.concatenate((reduced_embeddings, training_data_x), axis=1)\n",
    "\n",
    "X = X_combined  \n",
    "y = training_data[\"difficulty\"] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Régression Logistique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Logistic Regression model: 0.44479166666666664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_regression_model = LogisticRegression()\n",
    "\n",
    "# Train\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = logistic_regression_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of the Logistic Regression model:\", accuracy)\n",
    "\n",
    "# Delete the model to free up memory\n",
    "del logistic_regression_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM (Support Vector Machine) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the SVM model: 0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create an SVM classification model\n",
    "svm_model = SVC()\n",
    "\n",
    "# Train the model on the training set\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of the SVM model:\", accuracy)\n",
    "\n",
    "# Delete the model to free up memory\n",
    "del svm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arbres de Décision :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Decision Tree model: 0.34375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create a Decision Tree classification model\n",
    "decision_tree_model = DecisionTreeClassifier()\n",
    "\n",
    "# Train the model on the training set\n",
    "decision_tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = decision_tree_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of the Decision Tree model:\", accuracy)\n",
    "\n",
    "# Delete the model to free up memory\n",
    "del decision_tree_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forêts Aléatoires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Random Forest model: 0.43645833333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a Random Forest classification model\n",
    "random_forest_model = RandomForestClassifier()\n",
    "\n",
    "# Train the model on the training set\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = random_forest_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of the Random Forest model:\", accuracy)\n",
    "\n",
    "# Delete the model to free up memory\n",
    "del random_forest_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réseaux de Neurones (utilisant scikit-learn) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the MLP model: 0.3875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create an MLP classification model\n",
    "mlp_model = MLPClassifier()\n",
    "\n",
    "# Train the model on the training set\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = mlp_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of the MLP model:\", accuracy)\n",
    "\n",
    "# Delete the model to free up memory\n",
    "del mlp_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réseaux de Neurones Récursifs - RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the MLP model: 0.3416666666666667\n",
      "\n",
      "Classification Report for the MLP model:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.55      0.54       166\n",
      "           1       0.32      0.32      0.32       158\n",
      "           2       0.27      0.24      0.26       166\n",
      "           3       0.25      0.29      0.27       153\n",
      "           4       0.24      0.24      0.24       152\n",
      "           5       0.41      0.39      0.40       165\n",
      "\n",
      "    accuracy                           0.34       960\n",
      "   macro avg       0.34      0.34      0.34       960\n",
      "weighted avg       0.34      0.34      0.34       960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create an MLP classification model\n",
    "rnn_model = MLPClassifier(hidden_layer_sizes=(100,), activation='tanh', solver='adam', max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "rnn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rnn = rnn_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using accuracy_score\n",
    "accuracy_rnn = accuracy_score(y_test, y_pred_rnn)\n",
    "print(\"Accuracy of the MLP model:\", accuracy_rnn)\n",
    "\n",
    "# Evaluate the model using classification_report\n",
    "report_rnn = classification_report(y_test, y_pred_rnn)\n",
    "print(\"\\nClassification Report for the MLP model:\\n\", report_rnn)\n",
    "\n",
    "# Delete the model to free up memory\n",
    "del rnn_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
