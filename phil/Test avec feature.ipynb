{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>lexical_complexite</th>\n",
       "      <th>note_orthographe</th>\n",
       "      <th>char_length</th>\n",
       "      <th>word_length</th>\n",
       "      <th>type_token_ratio</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>complexite_texte</th>\n",
       "      <th>...</th>\n",
       "      <th>DET</th>\n",
       "      <th>PRON</th>\n",
       "      <th>NUM</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>VERB</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>SCONJ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Les coûts kilométriques réels peuvent diverger...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.194007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.160077</td>\n",
       "      <td>0.140152</td>\n",
       "      <td>0.467105</td>\n",
       "      <td>0.140152</td>\n",
       "      <td>0.339713</td>\n",
       "      <td>0.244565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Le bleu, c'est ma couleur préférée mais je n'a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.082334</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.036990</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Le test de niveau en français est sur le site ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.088078</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.039541</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.195804</td>\n",
       "      <td>0.081522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Est-ce que ton mari est aussi de Boston?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.062664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022959</td>\n",
       "      <td>0.026515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026515</td>\n",
       "      <td>0.193182</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dans les écoles de commerce, dans les couloirs...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.184993</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.130740</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.602941</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.288770</td>\n",
       "      <td>0.228261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  difficulty  \\\n",
       "id                                                                  \n",
       "0   Les coûts kilométriques réels peuvent diverger...           4   \n",
       "1   Le bleu, c'est ma couleur préférée mais je n'a...           0   \n",
       "2   Le test de niveau en français est sur le site ...           0   \n",
       "3            Est-ce que ton mari est aussi de Boston?           0   \n",
       "4   Dans les écoles de commerce, dans les couloirs...           2   \n",
       "\n",
       "    lexical_complexite  note_orthographe  char_length  word_length  \\\n",
       "id                                                                   \n",
       "0             0.194007          1.000000     0.160077     0.140152   \n",
       "1             0.082334          1.000000     0.036990     0.041667   \n",
       "2             0.088078          0.769231     0.039541     0.045455   \n",
       "3             0.062664          1.000000     0.022959     0.026515   \n",
       "4             0.184993          1.000000     0.130740     0.125000   \n",
       "\n",
       "    type_token_ratio  sentence_length  avg_word_length  complexite_texte  ...  \\\n",
       "id                                                                        ...   \n",
       "0           0.467105         0.140152         0.339713          0.244565  ...   \n",
       "1           1.000000         0.041667         0.204545          0.086957  ...   \n",
       "2           0.826923         0.045455         0.195804          0.081522  ...   \n",
       "3           1.000000         0.026515         0.193182          0.054348  ...   \n",
       "4           0.602941         0.125000         0.288770          0.228261  ...   \n",
       "\n",
       "         DET      PRON       NUM      NOUN  INTJ       ADP       ADJ  \\\n",
       "id                                                                     \n",
       "0   0.066667  0.000000  0.000000  0.311111   0.0  0.288889  0.066667   \n",
       "1   0.187500  0.125000  0.000000  0.125000   0.0  0.000000  0.000000   \n",
       "2   0.200000  0.000000  0.000000  0.400000   0.0  0.266667  0.000000   \n",
       "3   0.000000  0.100000  0.000000  0.300000   0.0  0.100000  0.000000   \n",
       "4   0.095238  0.047619  0.047619  0.238095   0.0  0.261905  0.047619   \n",
       "\n",
       "        VERB   PROPN  SCONJ  \n",
       "id                           \n",
       "0   0.088889  0.0000    0.0  \n",
       "1   0.125000  0.0625    0.0  \n",
       "2   0.066667  0.0000    0.0  \n",
       "3   0.100000  0.1000    0.1  \n",
       "4   0.095238  0.0000    0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "training_data = pd.read_csv(\"data/training_dataPhil.csv\", index_col=0)\n",
    "\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import transformers\n",
    "from transformers import CamembertForSequenceClassification, CamembertTokenizer, AutoModelForSequenceClassification, AutoTokenizer\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Charger le modèle CamemBERT\n",
    "model_name = \"dangvantuan/sentence-camembert-large\"\n",
    "#model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des données\n",
    "sentences = training_data['sentence'].tolist()\n",
    "labels = training_data['difficulty'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at dangvantuan/sentence-camembert-large and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "# Initialisation du tokeniseur et du modèle\n",
    "tokenizer = CamembertTokenizer.from_pretrained(model_name)\n",
    "model = CamembertForSequenceClassification.from_pretrained(model_name, num_labels=6)\n",
    "tokens = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NE PAS RUN !!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Époque 1/6: 100%|██████████| 300/300 [3:13:39<00:00, 38.73s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss moyenne pour l'époque: 1.2588747866948446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Époque 2/6: 100%|██████████| 300/300 [3:11:17<00:00, 38.26s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss moyenne pour l'époque: 0.8929875550667444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Époque 3/6: 100%|██████████| 300/300 [3:08:05<00:00, 37.62s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss moyenne pour l'époque: 0.6508233609795571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Époque 4/6: 100%|██████████| 300/300 [3:26:02<00:00, 41.21s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss moyenne pour l'époque: 0.4309373359878858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Époque 5/6: 100%|██████████| 300/300 [3:09:42<00:00, 37.94s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss moyenne pour l'époque: 0.31548847556114196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Époque 6/6: 100%|██████████| 300/300 [3:09:30<00:00, 37.90s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss moyenne pour l'époque: 0.18432556837797165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Récupération des tensors nécessaires du BatchEncoding\n",
    "input_ids = tokens['input_ids']\n",
    "attention_mask = tokens['attention_mask']\n",
    "\n",
    "# Create a training dataset\n",
    "train_dataset = torch.utils.data.TensorDataset(input_ids, attention_mask, torch.tensor(labels))\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Entraînement du modèle\n",
    "for epoch in range(6):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    # Utilisation de tqdm pour la barre de progression\n",
    "    for batch in tqdm(train_loader, desc=f\"Époque {epoch+1}/{6}\"):\n",
    "        input_ids_batch, attention_mask_batch, labels_batch = batch\n",
    "\n",
    "        # Construire le dictionnaire d'entrée pour le modèle\n",
    "        inputs = {'input_ids': input_ids_batch, 'attention_mask': attention_mask_batch, 'labels': labels_batch}\n",
    "           \n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Affichage de la perte moyenne pour l'époque\n",
    "    print(f\"Loss moyenne pour l'époque: {total_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.save(model.state_dict(), \"save4/modele.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Après l'entraînement de chaque époque\n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss,  # Vous pouvez sauvegarder la perte moyenne ou la dernière perte enregistrée\n",
    "    # Ajoutez d'autres métriques si nécessaire\n",
    "}, \"save4/complet.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UTILISER LE MODEL POST-TRAIN\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at dangvantuan/sentence-camembert-large and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CamembertForSequenceClassification(\n",
       "  (roberta): CamembertModel(\n",
       "    (embeddings): CamembertEmbeddings(\n",
       "      (word_embeddings): Embedding(32005, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): CamembertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x CamembertLayer(\n",
       "          (attention): CamembertAttention(\n",
       "            (self): CamembertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): CamembertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CamembertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): CamembertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): CamembertClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import CamembertForSequenceClassification, CamembertTokenizer\n",
    "import torch\n",
    "\n",
    "# Charger le tokenizer et le modèle pré-entraîné\n",
    "model_name = \"dangvantuan/sentence-camembert-large\"\n",
    "\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"dangvantuan/sentence-camembert-large\")\n",
    "model = CamembertForSequenceClassification.from_pretrained(\"dangvantuan/sentence-camembert-large\", num_labels=6)\n",
    "\n",
    "# Charger l'état sauvegardé de votre modèle post-entraîné\n",
    "model.load_state_dict(torch.load(\"save4/complet.pth\")['model_state_dict'])\n",
    "\n",
    "# Mettre le modèle en mode évaluation\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sentences:   0%|          | 0/4800 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Processing sentences: 100%|██████████| 4800/4800 [12:46<00:00,  6.26it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "sentences = training_data['sentence'].tolist()\n",
    "labels = training_data['difficulty'].tolist()\n",
    "\n",
    "# Initialiser une liste pour stocker les caractéristiques extraites\n",
    "all_features = []\n",
    "\n",
    "# Boucle sur les données avec une barre de progression\n",
    "for sentence in tqdm(sentences, desc=\"Processing sentences\"):\n",
    "    # Tokenisation et extraction de caractéristiques pour chaque phrase\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    outputs = model(**inputs)\n",
    "    features = outputs.logits.squeeze().detach().numpy()\n",
    "    \n",
    "    # Ajouter les caractéristiques à la liste\n",
    "    all_features.append(features)\n",
    "\n",
    "# Concaténer les caractéristiques en un seul tableau numpy\n",
    "#all_features = np.concatenate(all_features, axis=0)\n",
    "\n",
    "# Vérifier la forme des caractéristiques extraites\n",
    "#print(\"Shape of features:\", all_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4800"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_data_x = training_data.drop(columns=[\"difficulty\", \"sentence\",'note_orthographe'])\n",
    "combined_features = np.concatenate((all_features, training_data_x), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = combined_features  # Les embeddings camembert\n",
    "y = training_data[\"difficulty\"]  # Les niveaux de difficulté (étiquettes)\n",
    "\n",
    "# Effectuez la division en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle SVM : 0.9697916666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Créez un modèle SVM (classification)\n",
    "svm_model = SVC(C=10, gamma='scale', kernel='rbf')\n",
    "\n",
    "# Entraînez le modèle sur l'ensemble d'entraînement\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Évaluez la performance du modèle sur l'ensemble de test\n",
    "accuracy = svm_model.score(X_test, y_test)\n",
    "print(\"Précision du modèle SVM :\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"data/unlabelled_test_dataPhil.csv\", index_col=0)\n",
    "test_data2 = pd.read_csv(\"data/unlabelled_test_data.csv\", index_col=0)\n",
    "\n",
    "test_data = test_data.drop(columns=['note_orthographe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nous dûmes nous excuser des propos que nous eû...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vous ne pouvez pas savoir le plaisir que j'ai ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Et, paradoxalement, boire froid n'est pas la b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ce n'est pas étonnant, car c'est une saison my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Le corps de Golo lui-même, d'une essence aussi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence\n",
       "id                                                   \n",
       "0   Nous dûmes nous excuser des propos que nous eû...\n",
       "1   Vous ne pouvez pas savoir le plaisir que j'ai ...\n",
       "2   Et, paradoxalement, boire froid n'est pas la b...\n",
       "3   Ce n'est pas étonnant, car c'est une saison my...\n",
       "4   Le corps de Golo lui-même, d'une essence aussi..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sentences: 100%|██████████| 1200/1200 [03:10<00:00,  6.31it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "sentences = test_data['sentence'].tolist()\n",
    "\n",
    "# Initialiser une liste pour stocker les caractéristiques extraites\n",
    "all_features2 = []\n",
    "\n",
    "# Boucle sur les données avec une barre de progression\n",
    "for sentence in tqdm(sentences, desc=\"Processing sentences\"):\n",
    "    # Tokenisation et extraction de caractéristiques pour chaque phrase\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    outputs = model(**inputs)\n",
    "    features = outputs.logits.squeeze().detach().numpy()\n",
    "    \n",
    "    # Ajouter les caractéristiques à la liste\n",
    "    all_features2.append(features)\n",
    "\n",
    "# Concaténer les caractéristiques en un seul tableau numpy\n",
    "#all_features = np.concatenate(all_features, axis=0)\n",
    "\n",
    "# Vérifier la forme des caractéristiques extraites\n",
    "#print(\"Shape of features:\", all_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data_x = test_data.drop(columns=[\"sentence\",])\n",
    "combined_features = np.concatenate((all_features2, test_data_x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             sentence  difficulty\n",
      "id                                                               \n",
      "0   Nous dûmes nous excuser des propos que nous eû...           5\n",
      "1   Vous ne pouvez pas savoir le plaisir que j'ai ...           2\n",
      "2   Et, paradoxalement, boire froid n'est pas la b...           3\n",
      "3   Ce n'est pas étonnant, car c'est une saison my...           1\n",
      "4   Le corps de Golo lui-même, d'une essence aussi...           5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prédictions\n",
    "predicted_labels = svm_model.predict(combined_features)  # Assurez-vous d'extraire les caractéristiques des nouvelles phrases de la même manière que précédemment\n",
    "\n",
    "# Ajouter les prédictions au DataFrame\n",
    "test_data2['difficulty'] = predicted_labels\n",
    "\n",
    "# Afficher le DataFrame mis à jour\n",
    "print(test_data2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data2 = test_data2.drop(columns=['sentence'])\n",
    "difficulty_mapping = {\n",
    "    0: 'A1',\n",
    "    1: 'A2',\n",
    "    2: 'B1',\n",
    "    3: 'B2',\n",
    "    4: 'C1',\n",
    "    5: 'C2'\n",
    "}\n",
    "\n",
    "# Remplacez les valeurs dans la colonne \"difficulty\"\n",
    "test_data2['difficulty'] = test_data2['difficulty'].map(difficulty_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   difficulty\n",
      "id           \n",
      "0          C2\n",
      "1          B1\n",
      "2          B2\n",
      "3          A2\n",
      "4          C2\n",
      "5          C2\n",
      "6          A2\n",
      "7          A2\n",
      "8          C1\n",
      "9          A2\n",
      "10         A2\n",
      "11         A2\n",
      "12         B2\n",
      "13         C1\n",
      "14         A1\n",
      "15         A2\n",
      "16         B2\n",
      "17         A2\n",
      "18         A2\n",
      "19         A1\n",
      "20         C2\n",
      "21         C1\n",
      "22         C1\n",
      "23         C1\n",
      "24         B1\n",
      "25         C2\n",
      "26         A1\n",
      "27         A1\n",
      "28         C2\n",
      "29         B1\n"
     ]
    }
   ],
   "source": [
    "print(test_data2.head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data2.to_csv('philippe+features.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install Kaggle\n",
    "! pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle post-entraînement\n",
    "model = CamembertForSequenceClassification.from_pretrained(\"dangvantuan/sentence-camembert-large\", num_labels=6)\n",
    "\n",
    "# Tokeniser la phrase\n",
    "input_ids = tokenizer(sentences, return_tensors=\"pt\")[\"input_ids\"]\n",
    "attention_mask = tokenizer(sentences, return_tensors=\"pt\")[\"attention_mask\"]\n",
    "\n",
    "# Passez la phrase au modèle\n",
    "model.eval()  # Définir le modèle en mode évaluation\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "# Extraire les représentations tokenisées des sorties du modèle\n",
    "tokenized_text = outputs.last_hidden_state\n",
    "\n",
    "# Charger un autre modèle\n",
    "new_model = ...\n",
    "\n",
    "# Entraînez le nouveau modèle sur les représentations tokenisées\n",
    "new_model.fit(tokenized_text, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Charger le modèle post-entraînement\n",
    "model_name = \"dangvantuan/sentence-camembert-large\"\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Supposons que training_data contient vos données avec les phrases\n",
    "phrases = training_data['sentence'].tolist()\n",
    "\n",
    "# Générer des embeddings pour chaque phrase\n",
    "bert_embeddings = []\n",
    "for phrase in phrases:\n",
    "    # Tokeniser la phrase\n",
    "    input_ids = tokenizer(phrase, return_tensors=\"pt\")[\"input_ids\"]\n",
    "    attention_mask = tokenizer(phrase, return_tensors=\"pt\")[\"attention_mask\"]\n",
    "\n",
    "    # Passez la phrase au modèle\n",
    "    model.eval()  # Définir le modèle en mode évaluation\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Obtenir les prédictions du modèle\n",
    "    predictions = model.predict(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Calculer les embeddings\n",
    "    bert_embeddings.append(predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Charger le modèle\n",
    "model_name = \"dangvantuan/sentence-camembert-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modèle pré-entraîné Sentence-CamemBERT-Large en français"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /Users/phil/.cache/torch/sentence_transformers/dangvantuan_sentence-camembert-large. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Charger le modèle Sentence CamemBERT\n",
    "model_name = \"dangvantuan/sentence-camembert-large\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "\n",
    "# Supposons que training_data contient vos données avec les phrases\n",
    "phrases = training_data['sentence'].tolist()\n",
    "\n",
    "# Générer des embeddings pour chaque phrase\n",
    "bert_embeddings = model.encode(phrases)\n",
    "\n",
    "# Les embeddings sont maintenant stockés dans la variable 'embeddings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /Users/phil/.cache/torch/sentence_transformers/dangvantuan_sentence-camembert-large. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load pre-trained model\n",
    "model_name = \"dangvantuan/sentence-camembert-large\"\n",
    "sentence_model = SentenceTransformer(model_name)\n",
    "\n",
    "# Define a simple classifier\n",
    "class AdvancedClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_classes):\n",
    "        super(AdvancedClassifier, self).__init__()\n",
    "        # Définir les couches du réseau\n",
    "        self.fc1 = nn.Linear(embedding_dim, 512)  # Première couche cachée\n",
    "        self.relu = nn.ReLU()  # Fonction d'activation ReLU\n",
    "        self.fc2 = nn.Linear(512, 128)  # Deuxième couche cachée\n",
    "        self.fc3 = nn.Linear(128, num_classes)  # Couche de sortie\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))  # Activation de la première couche cachée\n",
    "        x = self.relu(self.fc2(x))  # Activation de la deuxième couche cachée\n",
    "        x = self.fc3(x)  # Couche de sortie\n",
    "        return x\n",
    "\n",
    "# Utiliser le classificateur avancé\n",
    "advanced_classifier = AdvancedClassifier(embedding_dim=1024, num_classes=6)\n",
    "\n",
    "# Mettre à jour CombinedModel pour utiliser le nouveau classificateur\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, sentence_model, classifier):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.sentence_model = sentence_model\n",
    "        self.classifier = classifier\n",
    "\n",
    "    def forward(self, sentences):\n",
    "        embeddings = self.sentence_model.encode(sentences, convert_to_tensor=True)\n",
    "        return self.classifier(embeddings)\n",
    "\n",
    "combined_model = CombinedModel(sentence_model, advanced_classifier)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = training_data[\"difficulty\"]\n",
    "# Supposons que y est votre vecteur de labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_data[\"sentence\"], y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from text_dataset import TextDataset\n",
    "\n",
    "\n",
    "# Créer des instances de Dataset pour PyTorch\n",
    "train_dataset = TextDataset(X_train, y_train)\n",
    "test_dataset = TextDataset(X_test, y_test)\n",
    "\n",
    "# Créer des DataLoader pour PyTorch\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,  # votre Dataset personnalisé pour l'entraînement\n",
    "    batch_size=32,  # Taille du lot\n",
    "    shuffle=True,   # Mélange des données à chaque époque\n",
    "    num_workers=4   # Utilisation de 4 sous-processus pour charger les données\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.3361645370721817\n",
      "Epoch 2, Loss: 0.9520346303780873\n",
      "Epoch 3, Loss: 0.661434571693341\n",
      "Epoch 4, Loss: 0.37359609454870224\n",
      "Epoch 5, Loss: 0.1603835804077486\n",
      "Epoch 6, Loss: 0.10519596920348703\n",
      "Epoch 7, Loss: 0.05917411423288286\n",
      "Epoch 8, Loss: 0.04578222093405202\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Définir le modèle et les paramètres d'entraînement\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(combined_model.parameters(), lr=0.001)\n",
    "\n",
    "# Boucle d'entraînement\n",
    "for epoch in range(8):  # Modifier le nombre d'époques si nécessaire\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Si votre modèle attend des tokens plutôt que des phrases brutes, vous devez tokeniser ici.\n",
    "        # Par exemple: inputs = tokenizer(inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        \n",
    "        outputs = combined_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on test data: 51.875%\n"
     ]
    }
   ],
   "source": [
    "combined_model.eval()  # Mettre le modèle en mode évaluation\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():  # Pas besoin de calculer les gradients lors de l'évaluation\n",
    "    for inputs, labels in test_loader:  # test_loader doit être défini comme DataLoader pour vos données de test\n",
    "        outputs = combined_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the model on test data: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of the model on test data: 50.625%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"path_to_save_model.pth\"\n",
    "torch.save(combined_model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CombinedModel(\n",
       "  (sentence_model): SentenceTransformer(\n",
       "    (0): Transformer({'max_seq_length': 514, 'do_lower_case': False}) with Transformer model: CamembertModel \n",
       "    (1): Pooling({'word_embedding_dimension': 1024, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  )\n",
       "  (classifier): SimpleClassifier(\n",
       "    (fc): Linear(in_features=1024, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_model.load_state_dict(torch.load(model_path))\n",
    "combined_model.eval()  # Ne pas oublier de mettre le modèle en mode évaluation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
