{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nous dûmes nous excuser des propos que nous eû...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vous ne pouvez pas savoir le plaisir que j'ai ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Et, paradoxalement, boire froid n'est pas la b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ce n'est pas étonnant, car c'est une saison my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Le corps de Golo lui-même, d'une essence aussi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence\n",
       "id                                                   \n",
       "0   Nous dûmes nous excuser des propos que nous eû...\n",
       "1   Vous ne pouvez pas savoir le plaisir que j'ai ...\n",
       "2   Et, paradoxalement, boire froid n'est pas la b...\n",
       "3   Ce n'est pas étonnant, car c'est une saison my...\n",
       "4   Le corps de Golo lui-même, d'une essence aussi..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the file path\n",
    "file_path_training = \"data/unlabelled_test_data.csv\"\n",
    "\n",
    "# Read the CSV file\n",
    "training_data = pd.read_csv(file_path_training, index_col=0)\n",
    "\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIVERSITE (POURCENTAGE DE MOT DIFFERENT - sans stepwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/phil/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/phil/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mesure la diversité lexicale en calculant le rapport entre le nombre de mots uniques et le nombre total de mots, et elle tient compte de la longueur moyenne des mots et des phrases.\n",
    "Le score de complexité renvoyé par cette fonction est basé sur ces mesures liées à la diversité lexicale et à la longueur des mots et des phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger la liste des stopwords\n",
    "stopwords_french = set(stopwords.words('french'))\n",
    "\n",
    "def preprocess_text(texte, remove_stopwords=True):\n",
    "    if not isinstance(texte, str):\n",
    "        raise ValueError(\"Le texte doit être une chaîne de caractères.\")\n",
    "\n",
    "    mots = word_tokenize(texte, language='french')\n",
    "    mots_low = [mot.lower() for mot in mots if mot.isalpha()]  # Filtrer les mots qui ne sont que des lettres\n",
    "\n",
    "    if remove_stopwords:\n",
    "        mots_low = [mot for mot in mots_low if mot not in stopwords_french]\n",
    "\n",
    "    return mots_low\n",
    "\n",
    "def diversite_lexicale_complexite(texte, remove_stopwords=True):\n",
    "    phrases = sent_tokenize(texte, language='french')\n",
    "    mots_low = preprocess_text(texte, remove_stopwords)\n",
    "    \n",
    "    if not mots_low or not phrases:\n",
    "        return float(0)  # Ou 0, selon ce qui est le plus approprié pour votre analyse\n",
    "    \n",
    "    nb_mots = len(mots_low)\n",
    "    nb_phrases = len(phrases)\n",
    "    longueur_moyenne_mot = sum(len(mot) for mot in mots_low) / nb_mots\n",
    "    longueur_moyenne_phrase = sum(len(phrase.split()) for phrase in phrases) / nb_phrases\n",
    "\n",
    "    lexical_diversity = len(set(mots_low)) / nb_mots\n",
    "\n",
    "    # Facteur de complexité basé sur la longueur moyenne des mots et des phrases\n",
    "    complexite = lexical_diversity * (1 + (longueur_moyenne_mot / 5)) * (1 + (longueur_moyenne_phrase / 10))\n",
    "    \n",
    "    return complexite\n",
    "\n",
    "# Exemple d'utilisation\n",
    "training_data['lexical_complexite'] = training_data['sentence'].apply(diversite_lexicale_complexite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>lexical_complexite</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>Au XIXe siècle la querelle du féminisme devien...</td>\n",
       "      <td>34.697699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>Le départ de Mlle Swann qui - en m'ôtant la ch...</td>\n",
       "      <td>31.742686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Car souvent dans l'une on trouve égaré un jour...</td>\n",
       "      <td>30.369515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>Et les mèches de ses cheveux roux crespelés pa...</td>\n",
       "      <td>25.834090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>Tôt dans l'année 1880, en dépit d'un doute bie...</td>\n",
       "      <td>25.663776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>Autour d'elles, sous elles, coulait un grand r...</td>\n",
       "      <td>24.755455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>Et les étoffes vivaient, dans cette passion du...</td>\n",
       "      <td>23.704762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>L'homme fait regarder son sexe comme un symbol...</td>\n",
       "      <td>22.190926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>Et se précipitant sur un livre de messe relié ...</td>\n",
       "      <td>21.774545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>Il n'était pas comme tant de gens qui par pare...</td>\n",
       "      <td>19.688920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>La validation de la segmentation et l'identifi...</td>\n",
       "      <td>19.371094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>Ce qui est à moi, ces quelques milliers de mor...</td>\n",
       "      <td>18.705603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Le corps de Golo lui-même, d'une essence aussi...</td>\n",
       "      <td>18.204000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>Rappelant que les propos du Premier ministre t...</td>\n",
       "      <td>18.031264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>Avec lui, par tous les royaumes de l'Europe, e...</td>\n",
       "      <td>17.506523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Et, dans le mirage confus où s'égaraient ses e...</td>\n",
       "      <td>17.137149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>De ce poste élevé elle participait avec entrai...</td>\n",
       "      <td>16.968889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>Le terme de géohistoire, défini par Fernand Br...</td>\n",
       "      <td>16.865398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>Brigitte Munier Il appartient à l'homme de ne ...</td>\n",
       "      <td>16.551775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>Et comme dans ce jeu où les Japonais s'amusent...</td>\n",
       "      <td>16.344691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>Je poursuivais jusque sur le talus qui, derriè...</td>\n",
       "      <td>16.305716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>Mais, comme il ne s'entendait guère plus en cu...</td>\n",
       "      <td>16.241938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>Il dépeignait de longues processions , cavalie...</td>\n",
       "      <td>15.824531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>Dans la plupart des cas, ils désignent moins l...</td>\n",
       "      <td>15.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>Du fait de la progression démographique et du ...</td>\n",
       "      <td>14.702857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Le comte, qui avait de l'usage, la pria de ne ...</td>\n",
       "      <td>14.553333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Par ailleurs, Yolande, qui habite à Paris, nou...</td>\n",
       "      <td>14.499231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>Sans honneur que précaire, sans liberté que pr...</td>\n",
       "      <td>14.489173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>Une étude portant sur 133 pays en développemen...</td>\n",
       "      <td>14.019310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>Le vieux rêve encyclopédique resurgit cependan...</td>\n",
       "      <td>13.911111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>Selon un sondage publié en mai de BVA et du Sy...</td>\n",
       "      <td>13.593832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>La \"marquise\" reprit un ton plus doux, car ell...</td>\n",
       "      <td>13.292083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>\"Nous sommes avant tout des êtres visuels, rét...</td>\n",
       "      <td>13.204211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>La formation, la santé et les relations social...</td>\n",
       "      <td>13.171304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Elle assurait ainsi à la fois leur repos et le...</td>\n",
       "      <td>13.127219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Richard Castelli Dès le XIXe siècle, l'usage d...</td>\n",
       "      <td>12.782442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>rène Jacob évoque son enfance à Genève (Suisse...</td>\n",
       "      <td>12.768000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>Ashton lui lançait en notes graves des provoca...</td>\n",
       "      <td>12.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Les plans de rigueur se succèdent dans de nomb...</td>\n",
       "      <td>12.621315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>Les consommateurs occidentaux sont tout prêts ...</td>\n",
       "      <td>12.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>L'accès à des moyens de transport, la mécanisa...</td>\n",
       "      <td>12.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>C'est à partir de Francis Bacon, et donc vers ...</td>\n",
       "      <td>12.532000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>Lucides, les adolescents mettent au point leur...</td>\n",
       "      <td>12.508421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>Ces pratiques de bon sens ne nous épargneront ...</td>\n",
       "      <td>12.486352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>Alors il réunit en son palais les bûcherons, l...</td>\n",
       "      <td>12.483951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>Dans une récente synthèse des recherches menée...</td>\n",
       "      <td>12.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Concentrés toute l'année sur les résultats sco...</td>\n",
       "      <td>12.430476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>Quand le berger revint à lui , il vit qu'il ét...</td>\n",
       "      <td>12.417778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>Pour expliquer ces différences, il est nécessa...</td>\n",
       "      <td>12.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>En 2017, 34, 6% de la population vit dans un m...</td>\n",
       "      <td>12.208254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  lexical_complexite\n",
       "id                                                                         \n",
       "355   Au XIXe siècle la querelle du féminisme devien...           34.697699\n",
       "259   Le départ de Mlle Swann qui - en m'ôtant la ch...           31.742686\n",
       "143   Car souvent dans l'une on trouve égaré un jour...           30.369515\n",
       "697   Et les mèches de ses cheveux roux crespelés pa...           25.834090\n",
       "1149  Tôt dans l'année 1880, en dépit d'un doute bie...           25.663776\n",
       "413   Autour d'elles, sous elles, coulait un grand r...           24.755455\n",
       "255   Et les étoffes vivaient, dans cette passion du...           23.704762\n",
       "25    L'homme fait regarder son sexe comme un symbol...           22.190926\n",
       "670   Et se précipitant sur un livre de messe relié ...           21.774545\n",
       "1197  Il n'était pas comme tant de gens qui par pare...           19.688920\n",
       "50    La validation de la segmentation et l'identifi...           19.371094\n",
       "553   Ce qui est à moi, ces quelques milliers de mor...           18.705603\n",
       "4     Le corps de Golo lui-même, d'une essence aussi...           18.204000\n",
       "772   Rappelant que les propos du Premier ministre t...           18.031264\n",
       "320   Avec lui, par tous les royaumes de l'Europe, e...           17.506523\n",
       "20    Et, dans le mirage confus où s'égaraient ses e...           17.137149\n",
       "751   De ce poste élevé elle participait avec entrai...           16.968889\n",
       "412   Le terme de géohistoire, défini par Fernand Br...           16.865398\n",
       "821   Brigitte Munier Il appartient à l'homme de ne ...           16.551775\n",
       "988   Et comme dans ce jeu où les Japonais s'amusent...           16.344691\n",
       "1078  Je poursuivais jusque sur le talus qui, derriè...           16.305716\n",
       "372   Mais, comme il ne s'entendait guère plus en cu...           16.241938\n",
       "939   Il dépeignait de longues processions , cavalie...           15.824531\n",
       "531   Dans la plupart des cas, ils désignent moins l...           15.080000\n",
       "526   Du fait de la progression démographique et du ...           14.702857\n",
       "47    Le comte, qui avait de l'usage, la pria de ne ...           14.553333\n",
       "193   Par ailleurs, Yolande, qui habite à Paris, nou...           14.499231\n",
       "1039  Sans honneur que précaire, sans liberté que pr...           14.489173\n",
       "511   Une étude portant sur 133 pays en développemen...           14.019310\n",
       "669   Le vieux rêve encyclopédique resurgit cependan...           13.911111\n",
       "740   Selon un sondage publié en mai de BVA et du Sy...           13.593832\n",
       "269   La \"marquise\" reprit un ton plus doux, car ell...           13.292083\n",
       "44    \"Nous sommes avant tout des êtres visuels, rét...           13.204211\n",
       "883   La formation, la santé et les relations social...           13.171304\n",
       "69    Elle assurait ainsi à la fois leur repos et le...           13.127219\n",
       "338   Richard Castelli Dès le XIXe siècle, l'usage d...           12.782442\n",
       "281   rène Jacob évoque son enfance à Genève (Suisse...           12.768000\n",
       "612   Ashton lui lançait en notes graves des provoca...           12.720000\n",
       "57    Les plans de rigueur se succèdent dans de nomb...           12.621315\n",
       "992   Les consommateurs occidentaux sont tout prêts ...           12.571429\n",
       "859   L'accès à des moyens de transport, la mécanisa...           12.533333\n",
       "1092  C'est à partir de Francis Bacon, et donc vers ...           12.532000\n",
       "666   Lucides, les adolescents mettent au point leur...           12.508421\n",
       "951   Ces pratiques de bon sens ne nous épargneront ...           12.486352\n",
       "347   Alors il réunit en son palais les bûcherons, l...           12.483951\n",
       "782   Dans une récente synthèse des recherches menée...           12.480000\n",
       "142   Concentrés toute l'année sur les résultats sco...           12.430476\n",
       "1062  Quand le berger revint à lui , il vit qu'il ét...           12.417778\n",
       "734   Pour expliquer ces différences, il est nécessa...           12.250000\n",
       "88    En 2017, 34, 6% de la population vit dans un m...           12.208254"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.sort_values(by=['lexical_complexite'], ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>lexical_complexite</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Il est 17h</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>Pouvez-vous m'aidez ?</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>Que se passe-t-il?</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Et toi ?</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>D'où viens-tu ?</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>Où habites-tu ?</td>\n",
       "      <td>1.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Si six scies scient six cyprès, six cent six s...</td>\n",
       "      <td>1.899733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>N'importe quoi.</td>\n",
       "      <td>2.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Es-tu prêt?</td>\n",
       "      <td>2.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>Quoi !</td>\n",
       "      <td>2.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>Oui, ça va, merci.</td>\n",
       "      <td>2.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>Vous êtes marié(e) ?</td>\n",
       "      <td>2.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>Elle a des amies.</td>\n",
       "      <td>2.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>Bonne idée.</td>\n",
       "      <td>2.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>Oui, bien sûr !</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>Je m'appelle Jean.</td>\n",
       "      <td>2.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>J'étais fier !</td>\n",
       "      <td>2.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>J'habite à New York.</td>\n",
       "      <td>2.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>Quel âge ont-ils ?</td>\n",
       "      <td>2.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>Je suis née aux Pays-Bas</td>\n",
       "      <td>2.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>Est-ce qu'il y a du pain?</td>\n",
       "      <td>2.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>Tu vas à l'université ?</td>\n",
       "      <td>2.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>A 55 ans, on est mort.</td>\n",
       "      <td>2.453333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>J'ai déjà mangé.</td>\n",
       "      <td>2.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Ça me sert à rien.</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Ce qui est faux.</td>\n",
       "      <td>2.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Est-ce que ça suffit?</td>\n",
       "      <td>2.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>Mais ce n'est pas le cas</td>\n",
       "      <td>2.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>Qu'as-tu mangé ?</td>\n",
       "      <td>2.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>Mon père est mort ici.</td>\n",
       "      <td>2.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>Elle est belge.</td>\n",
       "      <td>2.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>C'était super !</td>\n",
       "      <td>2.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>Aimerais-tu un verre?</td>\n",
       "      <td>2.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>Mais aujourd'hui, il a un peu peur.</td>\n",
       "      <td>2.606667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>Oui, nous allons bien.</td>\n",
       "      <td>2.613333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>Par ici, les mariés.</td>\n",
       "      <td>2.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Ici, c'est mon bureau.</td>\n",
       "      <td>2.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>Qu'est-ce que ça veut dire ?</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>Je n'aime pas le pain.</td>\n",
       "      <td>2.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>Il fait encore nuit.</td>\n",
       "      <td>2.706667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>On a de la chance !</td>\n",
       "      <td>2.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>Où est la salle 33 ?</td>\n",
       "      <td>2.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>Oui, et ils sont bons !</td>\n",
       "      <td>2.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Juste un moment.</td>\n",
       "      <td>2.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>Peux-tu répéter cela?</td>\n",
       "      <td>2.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>Oui, mais qui fait cela ?</td>\n",
       "      <td>2.773333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Excusez-moi, je me suis perdu. Pouvez-vous m'a...</td>\n",
       "      <td>2.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>OK, pas de problème.</td>\n",
       "      <td>2.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>C'était un saint homme.</td>\n",
       "      <td>2.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>Quel est cet animal ?</td>\n",
       "      <td>2.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  lexical_complexite\n",
       "id                                                                         \n",
       "27                                           Il est 17h            0.000000\n",
       "715                               Pouvez-vous m'aidez ?            0.000000\n",
       "984                                  Que se passe-t-il?            0.000000\n",
       "54                                             Et toi ?            0.000000\n",
       "172                                     D'où viens-tu ?            0.000000\n",
       "1170                                    Où habites-tu ?            1.820000\n",
       "21    Si six scies scient six cyprès, six cent six s...            1.899733\n",
       "70                                      N'importe quoi.            2.160000\n",
       "209                                         Es-tu prêt?            2.160000\n",
       "840                                              Quoi !            2.160000\n",
       "606                                  Oui, ça va, merci.            2.240000\n",
       "435                                Vous êtes marié(e) ?            2.240000\n",
       "1176                                  Elle a des amies.            2.240000\n",
       "546                                         Bonne idée.            2.280000\n",
       "262                                     Oui, bien sûr !            2.333333\n",
       "1111                                 Je m'appelle Jean.            2.340000\n",
       "551                                      J'étais fier !            2.340000\n",
       "434                                J'habite à New York.            2.380000\n",
       "647                                  Quel âge ont-ils ?            2.380000\n",
       "542                            Je suis née aux Pays-Bas            2.400000\n",
       "973                           Est-ce qu'il y a du pain?            2.400000\n",
       "662                             Tu vas à l'université ?            2.400000\n",
       "438                              A 55 ans, on est mort.            2.453333\n",
       "910                                    J'ai déjà mangé.            2.470000\n",
       "152                                  Ça me sert à rien.            2.500000\n",
       "157                                    Ce qui est faux.            2.520000\n",
       "10                                Est-ce que ça suffit?            2.520000\n",
       "920                            Mais ce n'est pas le cas            2.560000\n",
       "517                                    Qu'as-tu mangé ?            2.600000\n",
       "536                              Mon père est mort ici.            2.600000\n",
       "1054                                    Elle est belge.            2.600000\n",
       "1117                                    C'était super !            2.600000\n",
       "1101                              Aimerais-tu un verre?            2.600000\n",
       "360                 Mais aujourd'hui, il a un peu peur.            2.606667\n",
       "1003                             Oui, nous allons bien.            2.613333\n",
       "447                                Par ici, les mariés.            2.660000\n",
       "51                               Ici, c'est mon bureau.            2.660000\n",
       "813                        Qu'est-ce que ça veut dire ?            2.666667\n",
       "1192                             Je n'aime pas le pain.            2.700000\n",
       "1037                               Il fait encore nuit.            2.706667\n",
       "858                                 On a de la chance !            2.720000\n",
       "908                                Où est la salle 33 ?            2.720000\n",
       "402                             Oui, et ils sont bons !            2.720000\n",
       "305                                    Juste un moment.            2.730000\n",
       "929                               Peux-tu répéter cela?            2.730000\n",
       "767                           Oui, mais qui fait cela ?            2.773333\n",
       "32    Excusez-moi, je me suis perdu. Pouvez-vous m'a...            2.800000\n",
       "590                                OK, pas de problème.            2.800000\n",
       "905                             C'était un saint homme.            2.800000\n",
       "1011                              Quel est cet animal ?            2.800000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.sort_values(by=['lexical_complexite'], ascending=True).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VERIFICATION ORTHOGRAPHE (POURCENTAGE DE MOT DIFFERENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr-core-news-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.5.0/fr_core_news_sm-3.5.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from fr-core-news-sm==3.5.0) (3.5.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (1.0.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (3.0.6)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (0.9.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (0.4.1)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (1.23.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/phil/anaconda3/envs/ML/lib/python3.11/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->fr-core-news-sm==3.5.0) (2.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spellchecker import SpellChecker\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "spacy.cli.download(\"fr_core_news_sm\")\n",
    "nlp = spacy.load(\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import language_tool_python\n",
    "\n",
    "# Initialisation des outils\n",
    "tool = language_tool_python.LanguageTool('fr')\n",
    "\n",
    "def evaluer_orthographe_syntaxe(texte):\n",
    "    # Vérification avec LanguageTool\n",
    "    erreurs_language_tool = tool.check(texte)\n",
    "\n",
    "    # Compter les différents types d'erreurs\n",
    "    erreurs_orthographe = sum(1 for erreur in erreurs_language_tool if 'ORTHOGRAPH' in erreur.ruleId)\n",
    "    erreurs_grammaire = sum(1 for erreur in erreurs_language_tool if 'GRAMMAR' in erreur.ruleId)\n",
    "\n",
    "    # Analyse syntaxique avec spaCy\n",
    "    doc = nlp(texte)\n",
    "    erreurs_syntaxe = sum(1 for token in doc if token.dep_ == \"nsubj\" and token.head.pos_ != 'VERB')\n",
    "\n",
    "    # Calcul de la note\n",
    "    seuil_minimal_mots = 5\n",
    "    nombre_mots = max(len(texte.split()), seuil_minimal_mots)\n",
    "    poids_orthographe = 1.0  # Ajuster selon l'importance relative\n",
    "    poids_grammaire = 1.5  # Les erreurs grammaticales peuvent être plus graves\n",
    "    note_globale = max(1 - ((erreurs_orthographe * poids_orthographe + erreurs_grammaire * poids_grammaire + erreurs_syntaxe) / nombre_mots), 0)\n",
    "\n",
    "    return note_globale\n",
    "\n",
    "# Exemple d'utilisation\n",
    "training_data['note_orthographe'] = training_data['sentence'].apply(evaluer_orthographe_syntaxe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>lexical_complexite</th>\n",
       "      <th>note_orthographe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>Le paradis, je vous le dis.</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>Les maths font-elles peur aux femmes ?</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Ce qui est faux.</td>\n",
       "      <td>2.520000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>Je suis débutante.</td>\n",
       "      <td>3.640000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>C'était un saint homme.</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>Quel est cet animal ?</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>C'est ma meilleure amie</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>Elle est belge.</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>Y a moyen de moyenner.</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>C'est une fête chrétienne qui célèbre la naiss...</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>Mon père est mort ici.</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>C'est très difficile.</td>\n",
       "      <td>2.990000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>Je suis en vacances !</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>Aujourd'hui , c'est plus possible.</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>J'ai déjà mangé.</td>\n",
       "      <td>2.470000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>Nous sommes en vacances.</td>\n",
       "      <td>3.640000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>J'étais fier !</td>\n",
       "      <td>2.340000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>Savez-vous pourquoi ?</td>\n",
       "      <td>3.380000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Les divorces grimpent en flèche.</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>J'attends ta réponse</td>\n",
       "      <td>3.120000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>Moi, je suis français!</td>\n",
       "      <td>3.640000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>Et aujourd'hui, je suis artiste.</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>Vous faites de l'exercice physique</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>Je suis blanc ou noir</td>\n",
       "      <td>2.850000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>Je suis médecin.</td>\n",
       "      <td>3.120000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>C'est le fils mon père, mais ce n'est pas mon ...</td>\n",
       "      <td>3.920000</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Je suis une fille, je suis française et j'ai t...</td>\n",
       "      <td>4.515000</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>La multiplication des nouvelles technologies v...</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>J'adore ma grand-mère, elle très gentille.</td>\n",
       "      <td>3.520000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>C'est l'école qui doit le trouver.</td>\n",
       "      <td>3.360000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>A 55 ans, on est mort.</td>\n",
       "      <td>2.453333</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>Où est la salle 33 ?</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>Mais ce n'est pas le cas</td>\n",
       "      <td>2.560000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>Leur préservation est une affaire urgente.</td>\n",
       "      <td>4.373333</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>Ce sont des pères, point final.</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>Folio est la gardienne de l'appartement.</td>\n",
       "      <td>3.840000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>Oui, et ils sont bons !</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Papa est en voyage jusqu'à demain.</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>L'histoire de ce livre est incroyable</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Je suis tout à fait d'accord.</td>\n",
       "      <td>2.880000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>C'est une femme pleine de vertus.</td>\n",
       "      <td>3.413333</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>L'immense majorité des langues serait-elle con...</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>Là-bas tout le monde parle anglais ! Londres e...</td>\n",
       "      <td>3.520000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>Comme nous, ce sont des survivants.</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>C'est ce que j'ai cru comprendre.</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>C'était ce que je chantais le matin sous la do...</td>\n",
       "      <td>6.545714</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>Ils disaient que c'était grâce à eux que la fo...</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>C'est une question de point de vue.</td>\n",
       "      <td>3.513333</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>Mais cette année-là, l'hiver est très rude.</td>\n",
       "      <td>3.173333</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>Il est un boulot long et difficile.</td>\n",
       "      <td>3.853333</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  lexical_complexite  \\\n",
       "id                                                                            \n",
       "990                         Le paradis, je vous le dis.            3.200000   \n",
       "658              Les maths font-elles peur aux femmes ?            3.400000   \n",
       "157                                    Ce qui est faux.            2.520000   \n",
       "889                                  Je suis débutante.            3.640000   \n",
       "905                             C'était un saint homme.            2.800000   \n",
       "1011                              Quel est cet animal ?            2.800000   \n",
       "392                             C'est ma meilleure amie            3.220000   \n",
       "1054                                    Elle est belge.            2.600000   \n",
       "1098                             Y a moyen de moyenner.            2.900000   \n",
       "748   C'est une fête chrétienne qui célèbre la naiss...            4.800000   \n",
       "536                              Mon père est mort ici.            2.600000   \n",
       "686                               C'est très difficile.            2.990000   \n",
       "892                               Je suis en vacances !            3.900000   \n",
       "336                  Aujourd'hui , c'est plus possible.            3.300000   \n",
       "910                                    J'ai déjà mangé.            2.470000   \n",
       "1157                           Nous sommes en vacances.            3.640000   \n",
       "551                                      J'étais fier !            2.340000   \n",
       "838                               Savez-vous pourquoi ?            3.380000   \n",
       "275                    Les divorces grimpent en flèche.            3.700000   \n",
       "603                                J'attends ta réponse            3.120000   \n",
       "470                              Moi, je suis français!            3.640000   \n",
       "733                    Et aujourd'hui, je suis artiste.            3.600000   \n",
       "1194                 Vous faites de l'exercice physique            3.600000   \n",
       "746                               Je suis blanc ou noir            2.850000   \n",
       "541                                    Je suis médecin.            3.120000   \n",
       "1125  C'est le fils mon père, mais ce n'est pas mon ...            3.920000   \n",
       "211   Je suis une fille, je suis française et j'ai t...            4.515000   \n",
       "850   La multiplication des nouvelles technologies v...            5.600000   \n",
       "1042         J'adore ma grand-mère, elle très gentille.            3.520000   \n",
       "621                  C'est l'école qui doit le trouver.            3.360000   \n",
       "438                              A 55 ans, on est mort.            2.453333   \n",
       "908                                Où est la salle 33 ?            2.720000   \n",
       "920                            Mais ce n'est pas le cas            2.560000   \n",
       "942          Leur préservation est une affaire urgente.            4.373333   \n",
       "933                     Ce sont des pères, point final.            3.200000   \n",
       "1019           Folio est la gardienne de l'appartement.            3.840000   \n",
       "402                             Oui, et ils sont bons !            2.720000   \n",
       "224                  Papa est en voyage jusqu'à demain.            3.280000   \n",
       "1187              L'histoire de ce livre est incroyable            4.000000   \n",
       "30                        Je suis tout à fait d'accord.            2.880000   \n",
       "332                   C'est une femme pleine de vertus.            3.413333   \n",
       "384   L'immense majorité des langues serait-elle con...            5.500000   \n",
       "371   Là-bas tout le monde parle anglais ! Londres e...            3.520000   \n",
       "378                 Comme nous, ce sont des survivants.            4.000000   \n",
       "136                   C'est ce que j'ai cru comprendre.            3.680000   \n",
       "183   C'était ce que je chantais le matin sous la do...            6.545714   \n",
       "989   Ils disaient que c'était grâce à eux que la fo...            4.600000   \n",
       "975                 C'est une question de point de vue.            3.513333   \n",
       "528         Mais cette année-là, l'hiver est très rude.            3.173333   \n",
       "516                 Il est un boulot long et difficile.            3.853333   \n",
       "\n",
       "      note_orthographe  \n",
       "id                      \n",
       "990           0.666667  \n",
       "658           0.714286  \n",
       "157           0.800000  \n",
       "889           0.800000  \n",
       "905           0.800000  \n",
       "1011          0.800000  \n",
       "392           0.800000  \n",
       "1054          0.800000  \n",
       "1098          0.800000  \n",
       "748           0.800000  \n",
       "536           0.800000  \n",
       "686           0.800000  \n",
       "892           0.800000  \n",
       "336           0.800000  \n",
       "910           0.800000  \n",
       "1157          0.800000  \n",
       "551           0.800000  \n",
       "838           0.800000  \n",
       "275           0.800000  \n",
       "603           0.800000  \n",
       "470           0.800000  \n",
       "733           0.800000  \n",
       "1194          0.800000  \n",
       "746           0.800000  \n",
       "541           0.800000  \n",
       "1125          0.818182  \n",
       "211           0.818182  \n",
       "850           0.818182  \n",
       "1042          0.833333  \n",
       "621           0.833333  \n",
       "438           0.833333  \n",
       "908           0.833333  \n",
       "920           0.833333  \n",
       "942           0.833333  \n",
       "933           0.833333  \n",
       "1019          0.833333  \n",
       "402           0.833333  \n",
       "224           0.833333  \n",
       "1187          0.833333  \n",
       "30            0.833333  \n",
       "332           0.833333  \n",
       "384           0.833333  \n",
       "371           0.833333  \n",
       "378           0.833333  \n",
       "136           0.833333  \n",
       "183           0.842105  \n",
       "989           0.846154  \n",
       "975           0.857143  \n",
       "528           0.857143  \n",
       "516           0.857143  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.sort_values(by=['note_orthographe'], ascending=True).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUTRES ATTRIBUTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le score de complexité renvoyé par cette fonction est basé sur ces mesures liées à la structure grammaticale du texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/phil/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# LONGUEUR DES PHRASES\n",
    "def sentence_length(sentence):\n",
    "    return len(sentence.split())\n",
    "\n",
    "# LONGUEUR DES MOTS\n",
    "def average_word_length(sentence):\n",
    "    words = sentence.split()\n",
    "    return np.mean([len(word) for word in words]) if words else 0\n",
    "\n",
    "def type_token_ratio(sentence):\n",
    "    words = sentence.split()\n",
    "    return len(set(words)) / len(words) if words else 0\n",
    "\n",
    "# COMPLEXITE LEXICALE\n",
    "def complexite_texte(texte):\n",
    "    doc = nlp(texte)\n",
    "\n",
    "    # Mesures syntaxiques\n",
    "    nb_phrases = len(list(doc.sents))\n",
    "    profondeur_moyenne = sum(len(list(phrase.root.subtree)) for phrase in doc.sents) / nb_phrases if nb_phrases > 0 else 0\n",
    "\n",
    "    # Mesures grammaticales\n",
    "    temps_verbaux = {mot.tag_: 0 for mot in doc if mot.tag_ and \"VERB\" in mot.tag_}\n",
    "    for mot in doc:\n",
    "        if mot.tag_ and \"VERB\" in mot.tag_:\n",
    "            temps_verbaux[mot.tag_] += 1\n",
    "    diversite_temps_verbaux = len(temps_verbaux)\n",
    "\n",
    "    # Score de complexité combiné\n",
    "    complexite = profondeur_moyenne + diversite_temps_verbaux\n",
    "\n",
    "    return complexite\n",
    "\n",
    "# POS TAGGING\n",
    "def pos_tag_distribution(sentence):\n",
    "    if not isinstance(sentence, str):\n",
    "        raise ValueError(\"L'entrée doit être une chaîne de caractères.\")\n",
    "\n",
    "    doc = nlp(sentence)\n",
    "    pos_counts = {pos: 0 for pos in [token.pos_ for token in doc]}  # Initialise tous les tags possibles avec 0\n",
    "\n",
    "    for token in doc:\n",
    "        pos = token.pos_\n",
    "        pos_counts[pos] += 1\n",
    "\n",
    "    # Optionnel : normaliser par le nombre total de mots\n",
    "    total_mots = len(doc)\n",
    "    if total_mots > 0:\n",
    "        pos_counts_normalized = {pos: count / total_mots for pos, count in pos_counts.items()}\n",
    "        return pos_counts_normalized\n",
    "\n",
    "    return pos_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data['char_length'] = training_data['sentence'].apply(len)\n",
    "training_data['word_length'] = training_data['sentence'].apply(lambda x: len(x.split()))\n",
    "training_data['type_token_ratio'] = training_data['sentence'].apply(type_token_ratio)\n",
    "\n",
    "training_data['sentence_length'] = training_data['sentence'].apply(sentence_length)\n",
    "training_data['avg_word_length'] = training_data['sentence'].apply(average_word_length)\n",
    "training_data['complexite_texte'] = training_data['sentence'].apply(complexite_texte)\n",
    "training_data['pos_tags'] = training_data['sentence'].apply(pos_tag_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wm/59w25n_j2xg5z1dlk3fzxnl00000gn/T/ipykernel_22412/1114113631.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.4' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  training_data.at[index, tag] = count\n",
      "/var/folders/wm/59w25n_j2xg5z1dlk3fzxnl00000gn/T/ipykernel_22412/1114113631.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.1' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  training_data.at[index, tag] = count\n",
      "/var/folders/wm/59w25n_j2xg5z1dlk3fzxnl00000gn/T/ipykernel_22412/1114113631.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.3' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  training_data.at[index, tag] = count\n",
      "/var/folders/wm/59w25n_j2xg5z1dlk3fzxnl00000gn/T/ipykernel_22412/1114113631.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.125' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  training_data.at[index, tag] = count\n",
      "/var/folders/wm/59w25n_j2xg5z1dlk3fzxnl00000gn/T/ipykernel_22412/1114113631.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.0625' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  training_data.at[index, tag] = count\n",
      "/var/folders/wm/59w25n_j2xg5z1dlk3fzxnl00000gn/T/ipykernel_22412/1114113631.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.07692307692307693' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  training_data.at[index, tag] = count\n",
      "/var/folders/wm/59w25n_j2xg5z1dlk3fzxnl00000gn/T/ipykernel_22412/1114113631.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.012048192771084338' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  training_data.at[index, tag] = count\n",
      "/var/folders/wm/59w25n_j2xg5z1dlk3fzxnl00000gn/T/ipykernel_22412/1114113631.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.03614457831325301' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  training_data.at[index, tag] = count\n",
      "/var/folders/wm/59w25n_j2xg5z1dlk3fzxnl00000gn/T/ipykernel_22412/1114113631.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.18181818181818182' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  training_data.at[index, tag] = count\n",
      "/var/folders/wm/59w25n_j2xg5z1dlk3fzxnl00000gn/T/ipykernel_22412/1114113631.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.00847457627118644' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  training_data.at[index, tag] = count\n"
     ]
    }
   ],
   "source": [
    "unique_pos_tags = set()\n",
    "for pos_tags_dict in training_data['pos_tags']:\n",
    "    unique_pos_tags.update(pos_tags_dict.keys())\n",
    "\n",
    "# Initialize columns for each POS tag with default value 0\n",
    "for tag in ['PUNCT', 'ADV', 'CCONJ', 'X', 'AUX', 'DET', 'PRON', 'NUM', 'NOUN', 'INTJ', 'ADP', 'ADJ', 'VERB', 'PROPN', 'SCONJ']:\n",
    "    training_data[tag] = 0\n",
    "\n",
    "# Populate the columns with counts\n",
    "for index, row in training_data.iterrows():\n",
    "    for tag, count in row['pos_tags'].items():\n",
    "        if tag in training_data.columns:\n",
    "            training_data.at[index, tag] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = training_data.drop(['pos_tags'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>lexical_complexite</th>\n",
       "      <th>note_orthographe</th>\n",
       "      <th>char_length</th>\n",
       "      <th>word_length</th>\n",
       "      <th>type_token_ratio</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>complexite_texte</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>...</th>\n",
       "      <th>DET</th>\n",
       "      <th>PRON</th>\n",
       "      <th>NUM</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>VERB</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>SCONJ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nous dûmes nous excuser des propos que nous eû...</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>59</td>\n",
       "      <td>10</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>10</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vous ne pouvez pas savoir le plaisir que j'ai ...</td>\n",
       "      <td>5.485714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>79</td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Et, paradoxalement, boire froid n'est pas la b...</td>\n",
       "      <td>4.560000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>58</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ce n'est pas étonnant, car c'est une saison my...</td>\n",
       "      <td>4.560000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>55</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>5.222222</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Le corps de Golo lui-même, d'une essence aussi...</td>\n",
       "      <td>18.204000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>460</td>\n",
       "      <td>72</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>72</td>\n",
       "      <td>5.402778</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.072289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156627</td>\n",
       "      <td>0.120482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156627</td>\n",
       "      <td>0</td>\n",
       "      <td>0.120482</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.096386</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.036145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  lexical_complexite  \\\n",
       "id                                                                          \n",
       "0   Nous dûmes nous excuser des propos que nous eû...            4.700000   \n",
       "1   Vous ne pouvez pas savoir le plaisir que j'ai ...            5.485714   \n",
       "2   Et, paradoxalement, boire froid n'est pas la b...            4.560000   \n",
       "3   Ce n'est pas étonnant, car c'est une saison my...            4.560000   \n",
       "4   Le corps de Golo lui-même, d'une essence aussi...           18.204000   \n",
       "\n",
       "    note_orthographe  char_length  word_length  type_token_ratio  \\\n",
       "id                                                                 \n",
       "0           0.900000           59           10          0.900000   \n",
       "1           1.000000           79           14          1.000000   \n",
       "2           1.000000           58            9          1.000000   \n",
       "3           0.888889           55            9          1.000000   \n",
       "4           1.000000          460           72          0.791667   \n",
       "\n",
       "    sentence_length  avg_word_length  complexite_texte     PUNCT  ...  \\\n",
       "id                                                                ...   \n",
       "0                10         5.000000              11.0  0.000000  ...   \n",
       "1                14         4.714286              17.0  0.062500  ...   \n",
       "2                 9         5.555556              14.0  0.230769  ...   \n",
       "3                 9         5.222222              12.0  0.083333  ...   \n",
       "4                72         5.402778              84.0  0.072289  ...   \n",
       "\n",
       "         DET      PRON  NUM      NOUN  INTJ       ADP       ADJ      VERB  \\\n",
       "id                                                                          \n",
       "0   0.000000  0.400000  0.0  0.100000     0  0.100000  0.100000  0.300000   \n",
       "1   0.125000  0.187500  0.0  0.062500     0  0.062500  0.125000  0.250000   \n",
       "2   0.076923  0.000000  0.0  0.076923     0  0.000000  0.153846  0.076923   \n",
       "3   0.083333  0.166667  0.0  0.083333     0  0.000000  0.166667  0.000000   \n",
       "4   0.156627  0.120482  0.0  0.156627     0  0.120482  0.084337  0.096386   \n",
       "\n",
       "       PROPN     SCONJ  \n",
       "id                      \n",
       "0   0.000000  0.000000  \n",
       "1   0.000000  0.000000  \n",
       "2   0.000000  0.000000  \n",
       "3   0.000000  0.000000  \n",
       "4   0.012048  0.036145  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NORMALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Utiliser LabelEncoder pour encoder la variable cible \"difficulty\"\n",
    "label_encoder = LabelEncoder()\n",
    "training_data['difficulty'] = label_encoder.fit_transform(training_data['difficulty'])\n",
    "\n",
    "# Sélectionnez les caractéristiques numériques à normaliser\n",
    "numerical_features = ['lexical_complexite', 'note_orthographe', 'char_length', 'word_length', 'type_token_ratio', 'sentence_length', 'avg_word_length', 'complexite_texte']\n",
    "\n",
    "# Créez un scaler MinMax\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Appliquez la normalisation aux caractéristiques numériques\n",
    "training_data[numerical_features] = scaler.fit_transform(training_data[numerical_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.to_csv('data/unlabelled_test_dataPhil.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1388"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
