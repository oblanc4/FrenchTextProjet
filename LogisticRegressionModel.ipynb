{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oanaalexandrablanc/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/oanaalexandrablanc/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:62: UserWarning: Pandas requires version '1.3.4' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path\n",
    "file_path_test = \"unlabelled_test_data.csv\"\n",
    "file_path_training = \"training_data.csv\"\n",
    "\n",
    "# Read the CSV file\n",
    "unlabelled_test_data = pd.read_csv(file_path_test)\n",
    "training_data = pd.read_csv(file_path_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>processed_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Les coûts kilométriques réels peuvent diverger...</td>\n",
       "      <td>C1</td>\n",
       "      <td>le coût kilométrique réel pouvoir diverger sen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Le bleu, c'est ma couleur préférée mais je n'a...</td>\n",
       "      <td>A1</td>\n",
       "      <td>le bleu cest mon couleur préférer mais je naim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Le test de niveau en français est sur le site ...</td>\n",
       "      <td>A1</td>\n",
       "      <td>le test de niveau en français être sur le site...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Est-ce que ton mari est aussi de Boston?</td>\n",
       "      <td>A1</td>\n",
       "      <td>estce que ton mari être aussi de boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Dans les écoles de commerce, dans les couloirs...</td>\n",
       "      <td>B1</td>\n",
       "      <td>dans le école de commerce dans le couloir de p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           sentence difficulty  \\\n",
       "0   0  Les coûts kilométriques réels peuvent diverger...         C1   \n",
       "1   1  Le bleu, c'est ma couleur préférée mais je n'a...         A1   \n",
       "2   2  Le test de niveau en français est sur le site ...         A1   \n",
       "3   3           Est-ce que ton mari est aussi de Boston?         A1   \n",
       "4   4  Dans les écoles de commerce, dans les couloirs...         B1   \n",
       "\n",
       "                                  processed_sentence  \n",
       "0  le coût kilométrique réel pouvoir diverger sen...  \n",
       "1  le bleu cest mon couleur préférer mais je naim...  \n",
       "2  le test de niveau en français être sur le site...  \n",
       "3            estce que ton mari être aussi de boston  \n",
       "4  dans le école de commerce dans le couloir de p...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import spacy\n",
    "# Load the French spaCy model\n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Preprocess the text by:\n",
    "\n",
    "    - Lowercasing\n",
    "\n",
    "    - Removing punctuation\n",
    "\n",
    "    - Lemmatizing (using French spaCy model)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Lemmatization using spaCy\n",
    "    doc = nlp(text)\n",
    "    lemmatized_text = \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "    return lemmatized_text\n",
    "\n",
    "# Apply the preprocessing to the 'sentence' column\n",
    "\n",
    "training_data['processed_sentence'] = training_data['sentence'].apply(preprocess_text)\n",
    "\n",
    "# Display the first few rows of the updated dataframe\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Using TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(training_data['sentence'])\n",
    "y = training_data['difficulty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize and train the Logistic Regression model\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "logistic_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4625\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.51      0.68      0.58       166\n",
      "          A2       0.37      0.33      0.35       158\n",
      "          B1       0.44      0.31      0.37       166\n",
      "          B2       0.46      0.43      0.44       153\n",
      "          C1       0.44      0.44      0.44       152\n",
      "          C2       0.51      0.57      0.54       165\n",
      "\n",
      "    accuracy                           0.46       960\n",
      "   macro avg       0.46      0.46      0.45       960\n",
      "weighted avg       0.46      0.46      0.45       960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Predict the difficulty levels\n",
    "X_unlabelled = vectorizer.transform(unlabelled_test_data['sentence'])\n",
    "predicted_difficulties = logistic_model.predict(X_unlabelled)\n",
    "\n",
    "# Step 2: Create a new DataFrame\n",
    "predictions_df = pd.DataFrame({\n",
    "    'id': unlabelled_test_data['id'],\n",
    "    'predicted_difficulty': predicted_difficulties\n",
    "})\n",
    "\n",
    "# Step 3: Export to CSV\n",
    "#output_file_path = 'predicted_difficulties.csv'  \n",
    "#predictions_df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I want to extract some of the features from the training data so I can use them to train my model\n",
    "#training_data['type_token_ratio'] - This ratio compares the number of unique words (types) to the total number of words (tokens) in a text.\n",
    "#training_data['syntactic_complexity'] - counts commas as a proxy for complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/oanaalexandrablanc/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "def sentence_length(sentence):\n",
    "    return len(sentence.split())\n",
    "\n",
    "def average_word_length(sentence):\n",
    "    words = sentence.split()\n",
    "    return np.mean([len(word) for word in words]) if words else 0\n",
    "\n",
    "def type_token_ratio(sentence):\n",
    "    words = sentence.split()\n",
    "    return len(set(words)) / len(words) if words else 0\n",
    "\n",
    "def syntactic_complexity(sentence):\n",
    "    return sentence.count(',')\n",
    "\n",
    "def pos_tag_distribution(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    pos_counts = {}\n",
    "    for token in doc:\n",
    "        pos = token.pos_\n",
    "        pos_counts[pos] = pos_counts.get(pos, 0) + 1\n",
    "    return pos_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data['sentence_length'] = training_data['sentence'].apply(sentence_length)\n",
    "training_data['avg_word_length'] = training_data['sentence'].apply(average_word_length)\n",
    "training_data['type_token_ratio'] = training_data['sentence'].apply(type_token_ratio)\n",
    "training_data['syntactic_complexity'] = training_data['sentence'].apply(syntactic_complexity)\n",
    "training_data['pos_tags'] = training_data['sentence'].apply(pos_tag_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NUM', 'X', 'PROPN', 'VERB', 'SCONJ', 'INTJ', 'PRON', 'ADP', 'AUX', 'DET', 'ADV', 'NOUN', 'PUNCT', 'ADJ', 'CCONJ'}\n"
     ]
    }
   ],
   "source": [
    "unique_pos_tags = set()\n",
    "for pos_tags_dict in training_data['pos_tags']:\n",
    "    unique_pos_tags.update(pos_tags_dict.keys())\n",
    "\n",
    "print(unique_pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize columns for each POS tag with default value 0\n",
    "for tag in ['PUNCT', 'ADV', 'CCONJ', 'X', 'AUX', 'DET', 'PRON', 'NUM', 'NOUN', 'INTJ', 'ADP', 'ADJ', 'VERB', 'PROPN', 'SCONJ']:\n",
    "    training_data[tag] = 0\n",
    "\n",
    "# Populate the columns with counts\n",
    "for index, row in training_data.iterrows():\n",
    "    for tag, count in row['pos_tags'].items():\n",
    "        if tag in training_data.columns:\n",
    "            training_data.at[index, tag] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy.sparse as sp\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer with n-gram range\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_features=5000)\n",
    "\n",
    "# Fit and transform the text data using the updated TF-IDF vectorizer\n",
    "X_text_features = vectorizer.fit_transform(training_data['sentence'])\n",
    "\n",
    "# Existing code for your linguistic features\n",
    "X_linguistic_features = sp.csr_matrix(training_data[['sentence_length', 'avg_word_length', 'type_token_ratio', 'syntactic_complexity', 'PUNCT', 'ADV', 'CCONJ', 'X', 'AUX', 'DET', 'PRON', 'NUM', 'NOUN', 'INTJ', 'ADP', 'ADJ', 'VERB', 'PROPN', 'SCONJ']])\n",
    "\n",
    "# Combine the updated TF-IDF features with the linguistic features\n",
    "X_combined = sp.hstack([X_text_features, X_linguistic_features])\n",
    "\n",
    "# Create interaction terms\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_interactions = poly.fit_transform(X_combined.toarray())  # Convert to dense array for PolynomialFeatures\n",
    "\n",
    "# Now proceed with splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_interactions, training_data['difficulty'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oanaalexandrablanc/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Split the feature set with interaction terms into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_interactions, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Logistic Regression model using the new feature set\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "logistic_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4895833333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.58      0.77      0.66       166\n",
      "          A2       0.44      0.43      0.43       158\n",
      "          B1       0.46      0.40      0.43       166\n",
      "          B2       0.43      0.42      0.42       153\n",
      "          C1       0.45      0.47      0.46       152\n",
      "          C2       0.54      0.45      0.49       165\n",
      "\n",
      "    accuracy                           0.49       960\n",
      "   macro avg       0.48      0.49      0.48       960\n",
      "weighted avg       0.49      0.49      0.48       960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the same features for the unlabelled test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_test_data['sentence_length'] = unlabelled_test_data['sentence'].apply(sentence_length)\n",
    "unlabelled_test_data['avg_word_length'] = unlabelled_test_data['sentence'].apply(average_word_length)\n",
    "unlabelled_test_data['type_token_ratio'] = unlabelled_test_data['sentence'].apply(type_token_ratio)\n",
    "unlabelled_test_data['syntactic_complexity'] = unlabelled_test_data['sentence'].apply(syntactic_complexity)\n",
    "unlabelled_test_data['pos_tags'] = unlabelled_test_data['sentence'].apply(pos_tag_distribution)\n",
    "\n",
    "# Initialize columns for each POS tag with default value 0\n",
    "for tag in ['PUNCT', 'ADV', 'CCONJ', 'X', 'AUX', 'DET', 'PRON', 'NUM', 'NOUN', 'INTJ', 'ADP', 'ADJ', 'VERB', 'PROPN', 'SCONJ']:\n",
    "    unlabelled_test_data[tag] = 0\n",
    "\n",
    "# Populate the columns with counts\n",
    "for index, row in unlabelled_test_data.iterrows():\n",
    "    for tag, count in row['pos_tags'].items():\n",
    "        if tag in unlabelled_test_data.columns:\n",
    "            unlabelled_test_data.at[index, tag] = count\n",
    "\n",
    "# Transform the sentences using the same TF-IDF vectorizer\n",
    "X_unlabelled_text = vectorizer.transform(unlabelled_test_data['sentence'])\n",
    "X_unlabelled_linguistic = sp.csr_matrix(unlabelled_test_data[['sentence_length', 'avg_word_length', 'type_token_ratio', 'syntactic_complexity', 'PUNCT', 'ADV', 'CCONJ', 'X', 'AUX', 'DET', 'PRON', 'NUM', 'NOUN', 'INTJ', 'ADP', 'ADJ', 'VERB', 'PROPN', 'SCONJ']])\n",
    "X_unlabelled_combined = sp.hstack([X_unlabelled_text, X_unlabelled_linguistic])\n",
    "\n",
    "# Step 3: Predict the difficulty levels\n",
    "predicted_difficulties = logistic_model.predict(X_unlabelled_combined)\n",
    "\n",
    "# Step 4: Create a new DataFrame with predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'id': unlabelled_test_data['id'],\n",
    "    'predicted_difficulty': predicted_difficulties\n",
    "})\n",
    "\n",
    "# Step 5: Export to CSV\n",
    "#predictions_df.to_csv('predicted_difficulties2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now I'll try text embeddings\n",
    "#CamemBERT -> pip install transformers torch, pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.49895833333333334\n"
     ]
    }
   ],
   "source": [
    "from transformers import CamembertModel, CamembertTokenizer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load tokenizer and model for CamemBERT\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "model = CamembertModel.from_pretrained(\"camembert-base\")\n",
    "\n",
    "# Tokenize and encode sentences in the dataset\n",
    "inputs = tokenizer(list(training_data['sentence']), padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "input_ids = inputs['input_ids']\n",
    "\n",
    "# Create a DataLoader for batch processing\n",
    "batch_size = 8  # Adjust based on your system's capability\n",
    "dataset = TensorDataset(input_ids)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "# Generate embeddings in batches\n",
    "embeddings = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch[0]\n",
    "        outputs = model(input_ids)\n",
    "        batch_embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        embeddings.append(batch_embeddings)\n",
    "embeddings = torch.cat(embeddings, dim=0).numpy()\n",
    "\n",
    "# Dimensionality Reduction on Embeddings\n",
    "pca = PCA(n_components=50)  # Adjust n_components based on your dataset\n",
    "reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "# Normalize linguistic features\n",
    "scaler = StandardScaler()\n",
    "normalized_linguistic_features = scaler.fit_transform(training_data[['sentence_length', 'avg_word_length', 'type_token_ratio', 'syntactic_complexity', 'PUNCT', 'ADV', 'CCONJ', 'X', 'AUX', 'DET', 'PRON', 'NUM', 'NOUN', 'INTJ', 'ADP', 'ADJ', 'VERB', 'PROPN', 'SCONJ']].values)\n",
    "\n",
    "# Combine features\n",
    "combined_features = np.hstack((reduced_embeddings, normalized_linguistic_features))\n",
    "\n",
    "# Split data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features, training_data['difficulty'], test_size=0.2)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "# Map the computed weights to the corresponding class labels\n",
    "class_weights_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "# Train logistic regression model with class weights\n",
    "logistic_model = LogisticRegression(max_iter=1000, class_weight=class_weights_dict)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Cross-Validation Scores: [0.50729167 0.48854167 0.47604167 0.48125    0.47291667]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "parameters = {'C': [0.01, 0.1, 1, 10, 100], \n",
    "              'penalty': ['l1', 'l2'],\n",
    "              'solver': ['liblinear']}\n",
    "logistic_model = LogisticRegression(max_iter=1000, class_weight=class_weights_dict)\n",
    "clf = GridSearchCV(logistic_model, parameters, cv=5, error_score='raise')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(\"Best Hyperparameters:\", clf.best_params_)\n",
    "\n",
    "# Cross-Validation\n",
    "cross_val_scores = cross_val_score(clf, combined_features, training_data['difficulty'], cv=5)\n",
    "print(\"Cross-Validation Scores:\", cross_val_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The cross-validation scores indicate that the model's performance is not yet optimal, \n",
    "#as the accuracy scores across the different folds are hovering around 48% to 51%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oanaalexandrablanc/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/oanaalexandrablanc/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/oanaalexandrablanc/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/oanaalexandrablanc/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/oanaalexandrablanc/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/oanaalexandrablanc/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/oanaalexandrablanc/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/oanaalexandrablanc/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/oanaalexandrablanc/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:62: UserWarning: Pandas requires version '1.3.4' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/oanaalexandrablanc/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:62: UserWarning: Pandas requires version '1.3.4' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/oanaalexandrablanc/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:62: UserWarning: Pandas requires version '1.3.4' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/oanaalexandrablanc/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:62: UserWarning: Pandas requires version '1.3.4' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/oanaalexandrablanc/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:62: UserWarning: Pandas requires version '1.3.4' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/oanaalexandrablanc/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:62: UserWarning: Pandas requires version '1.3.4' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/oanaalexandrablanc/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:62: UserWarning: Pandas requires version '1.3.4' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/oanaalexandrablanc/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:62: UserWarning: Pandas requires version '1.3.4' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=1.49816047538945, penalty=l2; total time=   4.9s\n",
      "[CV] END .....................C=1.49816047538945, penalty=l2; total time=   5.0s\n",
      "[CV] END .....................C=1.49816047538945, penalty=l2; total time=   5.0s\n",
      "[CV] END .....................C=1.49816047538945, penalty=l2; total time=   5.1s\n",
      "[CV] END .....................C=1.49816047538945, penalty=l2; total time=   5.0s\n",
      "[CV] END ...................C=3.8028572256396647, penalty=l2; total time=   5.4s\n",
      "[CV] END ...................C=3.8028572256396647, penalty=l2; total time=   5.5s\n",
      "[CV] END ...................C=3.8028572256396647, penalty=l2; total time=   5.5s\n",
      "[CV] END ...................C=2.9279757672456204, penalty=l2; total time=   1.4s\n",
      "[CV] END ...................C=2.9279757672456204, penalty=l2; total time=   1.5s\n",
      "[CV] END ...................C=2.9279757672456204, penalty=l2; total time=   1.4s\n",
      "[CV] END ...................C=3.8028572256396647, penalty=l2; total time=   1.7s\n",
      "[CV] END ...................C=3.8028572256396647, penalty=l2; total time=   1.6s\n",
      "[CV] END ...................C=2.9279757672456204, penalty=l2; total time=   1.4s\n",
      "[CV] END ...................C=2.3946339367881464, penalty=l2; total time=   1.6s\n",
      "[CV] END ...................C=2.9279757672456204, penalty=l2; total time=   1.7s\n",
      "[CV] END ...................C=0.6240745617697461, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................C=0.6240745617697461, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................C=2.3946339367881464, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=2.3946339367881464, penalty=l2; total time=   1.4s\n",
      "[CV] END ...................C=2.3946339367881464, penalty=l2; total time=   1.4s\n",
      "[CV] END ...................C=2.3946339367881464, penalty=l2; total time=   1.4s\n",
      "[CV] END ...................C=0.6240745617697461, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................C=0.6240745617697461, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................C=0.6240745617697461, penalty=l2; total time=   0.8s\n",
      "[CV] END ..................C=0.23233444867279784, penalty=l2; total time=   0.5s\n",
      "[CV] END ..................C=0.23233444867279784, penalty=l2; total time=   0.5s\n",
      "[CV] END ...................C=0.6239780813448106, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=0.6239780813448106, penalty=l2; total time=   0.7s\n",
      "[CV] END ...................C=0.6239780813448106, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................C=0.6239780813448106, penalty=l2; total time=   0.7s\n",
      "[CV] END ...................C=0.6239780813448106, penalty=l2; total time=   0.7s\n",
      "[CV] END ..................C=0.23233444867279784, penalty=l2; total time=   0.4s\n",
      "[CV] END ..................C=0.23233444867279784, penalty=l2; total time=   0.4s\n",
      "[CV] END ..................C=0.23233444867279784, penalty=l2; total time=   0.5s\n",
      "[CV] END ...................C=3.4647045830997407, penalty=l2; total time=   1.3s\n",
      "[CV] END ...................C=3.4647045830997407, penalty=l2; total time=   1.3s\n",
      "[CV] END ...................C=3.4647045830997407, penalty=l2; total time=   1.3s\n",
      "[CV] END ...................C=3.4647045830997407, penalty=l2; total time=   1.4s\n",
      "[CV] END ....................C=2.404460046972835, penalty=l2; total time=   1.2s\n",
      "[CV] END ....................C=2.404460046972835, penalty=l2; total time=   1.0s\n",
      "[CV] END ....................C=2.404460046972835, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=3.4647045830997407, penalty=l2; total time=   1.4s\n",
      "[CV] END ..................C=0.08233797718320979, penalty=l2; total time=   0.3s\n",
      "[CV] END ..................C=0.08233797718320979, penalty=l2; total time=   0.3s\n",
      "[CV] END ..................C=0.08233797718320979, penalty=l2; total time=   0.3s\n",
      "[CV] END ....................C=2.404460046972835, penalty=l2; total time=   1.1s\n",
      "[CV] END ....................C=2.404460046972835, penalty=l2; total time=   1.2s\n",
      "[CV] END ....................C=2.832290311184182, penalty=l2; total time=   1.2s\n",
      "[CV] END ....................C=2.832290311184182, penalty=l2; total time=   1.2s\n",
      "[CV] END ....................C=2.832290311184182, penalty=l2; total time=   1.2s\n",
      "[CV] END ....................C=2.832290311184182, penalty=l2; total time=   1.3s\n",
      "[CV] END ....................C=2.832290311184182, penalty=l2; total time=   1.3s\n",
      "[CV] END ..................C=0.08233797718320979, penalty=l2; total time=   0.3s\n",
      "[CV] END ..................C=0.08233797718320979, penalty=l2; total time=   0.4s\n",
      "[CV] END ...................C=3.8796394086479773, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=3.8796394086479773, penalty=l2; total time=   1.3s\n",
      "[CV] END ....................C=3.329770563201687, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=3.8796394086479773, penalty=l2; total time=   1.3s\n",
      "[CV] END ...................C=3.8796394086479773, penalty=l2; total time=   1.4s\n",
      "[CV] END ...................C=3.8796394086479773, penalty=l2; total time=   1.3s\n",
      "[CV] END ....................C=3.329770563201687, penalty=l2; total time=   1.2s\n",
      "[CV] END ....................C=3.329770563201687, penalty=l2; total time=   1.3s\n",
      "[CV] END ...................C=0.8493564427131046, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................C=0.8493564427131046, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................C=0.8493564427131046, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................C=0.8493564427131046, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................C=0.7272998688284025, penalty=l2; total time=   0.7s\n",
      "[CV] END ...................C=0.8493564427131046, penalty=l2; total time=   0.8s\n",
      "[CV] END ....................C=3.329770563201687, penalty=l2; total time=   1.3s\n",
      "[CV] END ....................C=3.329770563201687, penalty=l2; total time=   1.3s\n",
      "[CV] END ...................C=0.7272998688284025, penalty=l2; total time=   0.7s\n",
      "[CV] END ...................C=0.7272998688284025, penalty=l2; total time=   0.7s\n",
      "[CV] END ...................C=0.7272998688284025, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................C=0.7272998688284025, penalty=l2; total time=   0.7s\n",
      "[CV] END ...................C=0.7336180394137353, penalty=l2; total time=   0.7s\n",
      "[CV] END ...................C=0.7336180394137353, penalty=l2; total time=   0.7s\n",
      "[CV] END ...................C=0.7336180394137353, penalty=l2; total time=   0.7s\n",
      "[CV] END ...................C=0.7336180394137353, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................C=0.7336180394137353, penalty=l2; total time=   0.8s\n",
      "[CV] END ....................C=1.216968971838151, penalty=l2; total time=   0.9s\n",
      "[CV] END ....................C=1.216968971838151, penalty=l2; total time=   1.0s\n",
      "[CV] END ....................C=1.216968971838151, penalty=l2; total time=   0.9s\n",
      "[CV] END ....................C=1.216968971838151, penalty=l2; total time=   0.9s\n",
      "[CV] END ....................C=1.216968971838151, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=2.0990257265289514, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=2.0990257265289514, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=2.0990257265289514, penalty=l2; total time=   1.1s\n",
      "[CV] END ....................C=1.727780074568463, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=2.0990257265289514, penalty=l2; total time=   1.1s\n",
      "[CV] END ....................C=1.727780074568463, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=2.0990257265289514, penalty=l2; total time=   1.1s\n",
      "[CV] END ....................C=1.727780074568463, penalty=l2; total time=   1.0s\n",
      "[CV] END ....................C=1.727780074568463, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.1649165607921677, penalty=l2; total time=   0.9s\n",
      "[CV] END ....................C=1.727780074568463, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=1.1649165607921677, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.1649165607921677, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................C=1.1649165607921677, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.1649165607921677, penalty=l2; total time=   0.9s\n",
      "[CV] END ....................C=2.447411578889518, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=0.5579754426081673, penalty=l2; total time=   0.7s\n",
      "[CV] END ...................C=0.5579754426081673, penalty=l2; total time=   0.7s\n",
      "[CV] END ...................C=0.5579754426081673, penalty=l2; total time=   0.7s\n",
      "[CV] END ....................C=2.447411578889518, penalty=l2; total time=   1.3s\n",
      "[CV] END ....................C=2.447411578889518, penalty=l2; total time=   1.2s\n",
      "[CV] END ....................C=2.447411578889518, penalty=l2; total time=   1.2s\n",
      "[CV] END ....................C=2.447411578889518, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=0.5579754426081673, penalty=l2; total time=   0.7s\n",
      "[CV] END ...................C=0.5579754426081673, penalty=l2; total time=   0.7s\n",
      "[CV] END ...................C=1.1685785941408726, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.1685785941408726, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.1685785941408726, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.1685785941408726, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.1685785941408726, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.4654473731747668, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=1.4654473731747668, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=1.4654473731747668, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.4654473731747668, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.4654473731747668, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.8242799368681437, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=1.8242799368681437, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=1.8242799368681437, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=1.8242799368681437, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=1.8242799368681437, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=3.1407038455720544, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=3.1407038455720544, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=3.1407038455720544, penalty=l2; total time=   1.3s\n",
      "[CV] END ...................C=0.7986951286334389, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................C=0.7986951286334389, penalty=l2; total time=   0.7s\n",
      "[CV] END ...................C=0.7986951286334389, penalty=l2; total time=   0.7s\n",
      "[CV] END ...................C=3.1407038455720544, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=3.1407038455720544, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=0.7986951286334389, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................C=0.7986951286334389, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................C=2.0569377536544464, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=2.0569377536544464, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=2.0569377536544464, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=2.0569377536544464, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=2.0569377536544464, penalty=l2; total time=   1.1s\n",
      "[CV] END .....................C=2.36965827544817, penalty=l2; total time=   1.1s\n",
      "[CV] END .....................C=2.36965827544817, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=0.1858016508799909, penalty=l2; total time=   0.4s\n",
      "[CV] END ...................C=0.1858016508799909, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=2.36965827544817, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=0.1858016508799909, penalty=l2; total time=   0.4s\n",
      "[CV] END ...................C=0.1858016508799909, penalty=l2; total time=   0.4s\n",
      "[CV] END ...................C=0.1858016508799909, penalty=l2; total time=   0.4s\n",
      "[CV] END .....................C=2.36965827544817, penalty=l2; total time=   1.1s\n",
      "[CV] END .....................C=2.36965827544817, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=0.6820964947491661, penalty=l2; total time=   0.7s\n",
      "[CV] END ...................C=0.6820964947491661, penalty=l2; total time=   0.7s\n",
      "[CV] END ...................C=2.4301794076057535, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=2.4301794076057535, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=2.4301794076057535, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=2.4301794076057535, penalty=l2; total time=   1.3s\n",
      "[CV] END ...................C=0.6820964947491661, penalty=l2; total time=   0.7s\n",
      "[CV] END ...................C=2.4301794076057535, penalty=l2; total time=   1.1s\n",
      "[CV] END ..................C=0.26020637194111806, penalty=l2; total time=   0.5s\n",
      "[CV] END ..................C=0.26020637194111806, penalty=l2; total time=   0.5s\n",
      "[CV] END ..................C=0.26020637194111806, penalty=l2; total time=   0.5s\n",
      "[CV] END ..................C=0.26020637194111806, penalty=l2; total time=   0.5s\n",
      "[CV] END ..................C=0.26020637194111806, penalty=l2; total time=   0.5s\n",
      "[CV] END ...................C=0.6820964947491661, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................C=0.6820964947491661, penalty=l2; total time=   0.7s\n",
      "[CV] END ....................C=3.795542149013333, penalty=l2; total time=   1.2s\n",
      "[CV] END ....................C=3.795542149013333, penalty=l2; total time=   1.2s\n",
      "[CV] END ....................C=3.795542149013333, penalty=l2; total time=   1.3s\n",
      "[CV] END ....................C=3.795542149013333, penalty=l2; total time=   1.3s\n",
      "[CV] END ....................C=3.795542149013333, penalty=l2; total time=   1.3s\n",
      "[CV] END ...................C=3.8625281322982374, penalty=l2; total time=   1.3s\n",
      "[CV] END ...................C=3.8625281322982374, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=3.8625281322982374, penalty=l2; total time=   1.4s\n",
      "[CV] END ...................C=3.8625281322982374, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=3.2335893924658445, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=3.2335893924658445, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=1.2184550766934827, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=3.2335893924658445, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=3.8625281322982374, penalty=l2; total time=   1.4s\n",
      "[CV] END ...................C=3.2335893924658445, penalty=l2; total time=   1.3s\n",
      "[CV] END ...................C=3.2335893924658445, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=1.2184550766934827, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=0.3906884560255355, penalty=l2; total time=   0.6s\n",
      "[CV] END ...................C=0.3906884560255355, penalty=l2; total time=   0.6s\n",
      "[CV] END ...................C=0.3906884560255355, penalty=l2; total time=   0.6s\n",
      "[CV] END ...................C=0.3906884560255355, penalty=l2; total time=   0.6s\n",
      "[CV] END ...................C=1.2184550766934827, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.2184550766934827, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.2184550766934827, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=0.3906884560255355, penalty=l2; total time=   0.6s\n",
      "[CV] END ...................C=2.7369321060486276, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=2.7369321060486276, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=1.7606099749584052, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=2.7369321060486276, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=2.7369321060486276, penalty=l2; total time=   1.3s\n",
      "[CV] END ...................C=2.7369321060486276, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=1.7606099749584052, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=1.7606099749584052, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=0.4881529393791153, penalty=l2; total time=   0.6s\n",
      "[CV] END ...................C=0.4881529393791153, penalty=l2; total time=   0.6s\n",
      "[CV] END ...................C=0.4881529393791153, penalty=l2; total time=   0.6s\n",
      "[CV] END ...................C=0.4881529393791153, penalty=l2; total time=   0.6s\n",
      "[CV] END ...................C=0.4881529393791153, penalty=l2; total time=   0.6s\n",
      "[CV] END ...................C=1.7606099749584052, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=1.7606099749584052, penalty=l2; total time=   1.0s\n",
      "[CV] END ..................C=0.13755408446087358, penalty=l2; total time=   0.4s\n",
      "[CV] END ...................C=1.9807076404450807, penalty=l2; total time=   1.1s\n",
      "[CV] END ..................C=0.13755408446087358, penalty=l2; total time=   0.4s\n",
      "[CV] END ..................C=0.13755408446087358, penalty=l2; total time=   0.4s\n",
      "[CV] END ..................C=0.13755408446087358, penalty=l2; total time=   0.4s\n",
      "[CV] END ..................C=0.13755408446087358, penalty=l2; total time=   0.4s\n",
      "[CV] END ...................C=1.9807076404450807, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=1.9807076404450807, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=1.9807076404450807, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=1.9807076404450807, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=3.6372816083151283, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=1.0351199264000677, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................C=1.0351199264000677, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................C=3.6372816083151283, penalty=l2; total time=   1.4s\n",
      "[CV] END ...................C=3.6372816083151283, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=1.0351199264000677, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=3.6372816083151283, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=3.6372816083151283, penalty=l2; total time=   1.3s\n",
      "[CV] END ...................C=1.0351199264000677, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.0351199264000677, penalty=l2; total time=   0.9s\n",
      "[CV] END ....................C=2.650089137415928, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=1.2468443043576438, penalty=l2; total time=   0.9s\n",
      "[CV] END ....................C=2.650089137415928, penalty=l2; total time=   1.1s\n",
      "[CV] END ....................C=2.650089137415928, penalty=l2; total time=   1.2s\n",
      "[CV] END ....................C=2.650089137415928, penalty=l2; total time=   1.2s\n",
      "[CV] END ....................C=2.650089137415928, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=1.2468443043576438, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................C=1.2468443043576438, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.2468443043576438, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=1.2468443043576438, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=2.0802720847112433, penalty=l2; total time=   1.4s\n",
      "[CV] END ...................C=2.0802720847112433, penalty=l2; total time=   1.4s\n",
      "[CV] END ...................C=2.0802720847112433, penalty=l2; total time=   1.4s\n",
      "[CV] END ...................C=2.0802720847112433, penalty=l2; total time=   1.3s\n",
      "[CV] END ...................C=2.0802720847112433, penalty=l2; total time=   1.4s\n",
      "[CV] END ...................C=2.1868411173731186, penalty=l2; total time=   1.4s\n",
      "[CV] END ...................C=2.1868411173731186, penalty=l2; total time=   1.3s\n",
      "[CV] END ...................C=0.7394178221021082, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................C=2.1868411173731186, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=0.7394178221021082, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=2.1868411173731186, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=0.7394178221021082, penalty=l2; total time=   0.7s\n",
      "[CV] END ...................C=0.7394178221021082, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................C=2.1868411173731186, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=0.7394178221021082, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=3.8783385110582342, penalty=l2; total time=   1.4s\n",
      "[CV] END ...................C=3.8783385110582342, penalty=l2; total time=   1.5s\n",
      "[CV] END ...................C=3.8783385110582342, penalty=l2; total time=   1.5s\n",
      "[CV] END ...................C=3.8783385110582342, penalty=l2; total time=   1.8s\n",
      "[CV] END ....................C=3.100531293444458, penalty=l2; total time=   1.6s\n",
      "[CV] END ....................C=3.100531293444458, penalty=l2; total time=   1.6s\n",
      "[CV] END ...................C=3.8783385110582342, penalty=l2; total time=   1.8s\n",
      "[CV] END ....................C=3.100531293444458, penalty=l2; total time=   1.4s\n",
      "[CV] END ....................C=3.100531293444458, penalty=l2; total time=   1.2s\n",
      "[CV] END ....................C=3.100531293444458, penalty=l2; total time=   1.3s\n",
      "[CV] END ...................C=3.7579957662567565, penalty=l2; total time=   1.4s\n",
      "[CV] END ...................C=3.7579957662567565, penalty=l2; total time=   1.5s\n",
      "[CV] END ...................C=3.7579957662567565, penalty=l2; total time=   1.3s\n",
      "[CV] END ...................C=3.7579957662567565, penalty=l2; total time=   1.4s\n",
      "[CV] END ...................C=3.7579957662567565, penalty=l2; total time=   1.5s\n",
      "[CV] END ...................C=3.5793094017105953, penalty=l2; total time=   1.4s\n",
      "[CV] END ...................C=3.5793094017105953, penalty=l2; total time=   1.3s\n",
      "[CV] END ...................C=3.5793094017105953, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=3.5793094017105953, penalty=l2; total time=   1.3s\n",
      "[CV] END ...................C=3.5793094017105953, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=2.3915999152443406, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=2.3915999152443406, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=2.3915999152443406, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=2.3915999152443406, penalty=l2; total time=   1.2s\n",
      "[CV] END ....................C=0.353970008207678, penalty=l2; total time=   0.7s\n",
      "[CV] END ....................C=0.353970008207678, penalty=l2; total time=   0.7s\n",
      "[CV] END ...................C=2.3915999152443406, penalty=l2; total time=   1.5s\n",
      "[CV] END ...................C=3.6874969400924673, penalty=l2; total time=   1.6s\n",
      "[CV] END ....................C=0.353970008207678, penalty=l2; total time=   0.6s\n",
      "[CV] END ...................C=3.6874969400924673, penalty=l2; total time=   1.6s\n",
      "[CV] END ...................C=3.6874969400924673, penalty=l2; total time=   1.6s\n",
      "[CV] END ...................C=3.6874969400924673, penalty=l2; total time=   1.5s\n",
      "[CV] END ...................C=3.6874969400924673, penalty=l2; total time=   1.5s\n",
      "[CV] END ....................C=0.353970008207678, penalty=l2; total time=   0.6s\n",
      "[CV] END ....................C=0.353970008207678, penalty=l2; total time=   0.6s\n",
      "[CV] END ..................C=0.18090915564215226, penalty=l2; total time=   0.4s\n",
      "[CV] END ..................C=0.18090915564215226, penalty=l2; total time=   0.5s\n",
      "[CV] END ..................C=0.18090915564215226, penalty=l2; total time=   0.4s\n",
      "[CV] END ...................C=0.7839314496765808, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................C=0.7839314496765808, penalty=l2; total time=   0.7s\n",
      "[CV] END ...................C=0.7839314496765808, penalty=l2; total time=   0.7s\n",
      "[CV] END ...................C=0.7839314496765808, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................C=0.7839314496765808, penalty=l2; total time=   0.8s\n",
      "[CV] END ..................C=0.18090915564215226, penalty=l2; total time=   0.4s\n",
      "[CV] END ..................C=0.18090915564215226, penalty=l2; total time=   0.5s\n",
      "[CV] END ...................C=1.3013213230530574, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.3013213230530574, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.3013213230530574, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.3013213230530574, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.3013213230530574, penalty=l2; total time=   1.0s\n",
      "[CV] END ....................C=1.554709158757928, penalty=l2; total time=   0.9s\n",
      "[CV] END ....................C=1.554709158757928, penalty=l2; total time=   1.1s\n",
      "[CV] END ....................C=1.554709158757928, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=1.0853961270955836, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................C=1.0853961270955836, penalty=l2; total time=   0.9s\n",
      "[CV] END ....................C=1.554709158757928, penalty=l2; total time=   1.0s\n",
      "[CV] END ....................C=1.554709158757928, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=1.0853961270955836, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=1.0853961270955836, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.0853961270955836, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=3.3149500366077174, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=1.4270133067743571, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.4270133067743571, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.4270133067743571, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=3.3149500366077174, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=3.3149500366077174, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=3.3149500366077174, penalty=l2; total time=   1.3s\n",
      "[CV] END ...................C=3.3149500366077174, penalty=l2; total time=   1.5s\n",
      "[CV] END ...................C=1.4270133067743571, penalty=l2; total time=   1.0s\n",
      "[CV] END ....................C=1.123738038749523, penalty=l2; total time=   0.9s\n",
      "[CV] END ....................C=1.123738038749523, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.4270133067743571, penalty=l2; total time=   1.0s\n",
      "[CV] END ....................C=1.123738038749523, penalty=l2; total time=   0.9s\n",
      "[CV] END ....................C=1.123738038749523, penalty=l2; total time=   0.8s\n",
      "[CV] END ....................C=1.123738038749523, penalty=l2; total time=   0.9s\n",
      "[CV] END ....................C=2.170784332632994, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=0.5636968998990506, penalty=l2; total time=   0.7s\n",
      "[CV] END ...................C=0.5636968998990506, penalty=l2; total time=   0.6s\n",
      "[CV] END ....................C=2.170784332632994, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=0.5636968998990506, penalty=l2; total time=   0.7s\n",
      "[CV] END ....................C=2.170784332632994, penalty=l2; total time=   1.0s\n",
      "[CV] END ....................C=2.170784332632994, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=0.5636968998990506, penalty=l2; total time=   0.7s\n",
      "[CV] END ....................C=2.170784332632994, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=0.5636968998990506, penalty=l2; total time=   0.6s\n",
      "[CV] END ...................C=0.2982025747190833, penalty=l2; total time=   0.5s\n",
      "[CV] END ...................C=0.2982025747190833, penalty=l2; total time=   0.5s\n",
      "[CV] END ...................C=0.2982025747190833, penalty=l2; total time=   0.5s\n",
      "[CV] END ...................C=3.2087879230161587, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=3.2087879230161587, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=3.2087879230161587, penalty=l2; total time=   1.3s\n",
      "[CV] END ...................C=3.2087879230161587, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=0.2982025747190833, penalty=l2; total time=   0.5s\n",
      "[CV] END ...................C=3.2087879230161587, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=0.2982025747190833, penalty=l2; total time=   0.5s\n",
      "[CV] END ....................C=3.947547746402069, penalty=l2; total time=   1.3s\n",
      "[CV] END ....................C=3.947547746402069, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=3.0889790771866297, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=3.0889790771866297, penalty=l2; total time=   1.3s\n",
      "[CV] END ....................C=3.947547746402069, penalty=l2; total time=   1.3s\n",
      "[CV] END ....................C=3.947547746402069, penalty=l2; total time=   1.4s\n",
      "[CV] END ...................C=3.0889790771866297, penalty=l2; total time=   1.4s\n",
      "[CV] END ....................C=3.947547746402069, penalty=l2; total time=   1.4s\n",
      "[CV] END .................C=0.022088468494409597, penalty=l2; total time=   0.2s\n",
      "[CV] END .................C=0.022088468494409597, penalty=l2; total time=   0.2s\n",
      "[CV] END .................C=0.022088468494409597, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=0.7948627261366896, penalty=l2; total time=   0.7s\n",
      "[CV] END ...................C=0.7948627261366896, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................C=0.7948627261366896, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................C=0.7948627261366896, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................C=0.7948627261366896, penalty=l2; total time=   0.8s\n",
      "[CV] END .................C=0.022088468494409597, penalty=l2; total time=   0.2s\n",
      "[CV] END .................C=0.022088468494409597, penalty=l2; total time=   0.2s\n",
      "[CV] END ...................C=3.0889790771866297, penalty=l2; total time=   1.3s\n",
      "[CV] END ...................C=3.0889790771866297, penalty=l2; total time=   1.3s\n",
      "[CV] END ...................C=3.2618457138193366, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=3.2618457138193366, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=3.2618457138193366, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=3.2618457138193366, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=2.8274293753904685, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=3.2618457138193366, penalty=l2; total time=   1.3s\n",
      "[CV] END ...................C=2.8274293753904685, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=2.8274293753904685, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=2.8274293753904685, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=2.8274293753904685, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=2.9160286721639492, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=2.9160286721639492, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=2.9160286721639492, penalty=l2; total time=   1.3s\n",
      "[CV] END ....................C=3.085081386743783, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=2.9160286721639492, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=2.9160286721639492, penalty=l2; total time=   1.4s\n",
      "[CV] END ..................C=0.29617860693636144, penalty=l2; total time=   0.5s\n",
      "[CV] END ..................C=0.29617860693636144, penalty=l2; total time=   0.5s\n",
      "[CV] END ..................C=0.29617860693636144, penalty=l2; total time=   0.5s\n",
      "[CV] END ..................C=0.29617860693636144, penalty=l2; total time=   0.5s\n",
      "[CV] END ....................C=3.085081386743783, penalty=l2; total time=   1.1s\n",
      "[CV] END ....................C=3.085081386743783, penalty=l2; total time=   1.3s\n",
      "[CV] END ....................C=3.085081386743783, penalty=l2; total time=   1.2s\n",
      "[CV] END ..................C=0.29617860693636144, penalty=l2; total time=   0.5s\n",
      "[CV] END ....................C=3.085081386743783, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=1.4338629141770904, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.4338629141770904, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=1.4338629141770904, penalty=l2; total time=   1.0s\n",
      "[CV] END ..................C=0.46347623810051886, penalty=l2; total time=   0.6s\n",
      "[CV] END ..................C=0.46347623810051886, penalty=l2; total time=   0.6s\n",
      "[CV] END ..................C=0.46347623810051886, penalty=l2; total time=   0.6s\n",
      "[CV] END ...................C=1.4338629141770904, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=1.4338629141770904, penalty=l2; total time=   1.0s\n",
      "[CV] END ..................C=0.46347623810051886, penalty=l2; total time=   0.6s\n",
      "[CV] END ..................C=0.46347623810051886, penalty=l2; total time=   0.7s\n",
      "[CV] END ....................C=3.452413703502374, penalty=l2; total time=   1.2s\n",
      "[CV] END ....................C=3.452413703502374, penalty=l2; total time=   1.3s\n",
      "[CV] END ....................C=3.452413703502374, penalty=l2; total time=   1.3s\n",
      "[CV] END ....................C=3.452413703502374, penalty=l2; total time=   1.3s\n",
      "[CV] END ....................C=3.452413703502374, penalty=l2; total time=   1.5s\n",
      "[CV] END ...................C=2.4931925073102317, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=2.4931925073102317, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=2.4931925073102317, penalty=l2; total time=   1.0s\n",
      "[CV] END ..................C=0.25423340114409454, penalty=l2; total time=   0.5s\n",
      "[CV] END ...................C=1.3235920994105967, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=2.4931925073102317, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=1.3235920994105967, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=2.4931925073102317, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=1.3235920994105967, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=1.3235920994105967, penalty=l2; total time=   0.9s\n",
      "[CV] END ..................C=0.25423340114409454, penalty=l2; total time=   0.5s\n",
      "[CV] END ...................C=1.3235920994105967, penalty=l2; total time=   1.0s\n",
      "[CV] END ..................C=0.25423340114409454, penalty=l2; total time=   0.5s\n",
      "[CV] END ..................C=0.25423340114409454, penalty=l2; total time=   0.5s\n",
      "[CV] END ..................C=0.25423340114409454, penalty=l2; total time=   0.5s\n",
      "[CV] END ...................C=1.2439292868626488, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................C=1.2439292868626488, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................C=1.2439292868626488, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.2439292868626488, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.2439292868626488, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=1.3007332881069882, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.3007332881069882, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.3007332881069882, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.3007332881069882, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.3007332881069882, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=2.9184247133522563, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=2.9184247133522563, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=2.9184247133522563, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=2.9184247133522563, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=2.9184247133522563, penalty=l2; total time=   1.3s\n",
      "[CV] END ...................C=2.5502298854208525, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=2.5502298854208525, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=2.5502298854208525, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=2.5502298854208525, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=2.5502298854208525, penalty=l2; total time=   1.2s\n",
      "[CV] END ....................C=3.548850970305306, penalty=l2; total time=   1.3s\n",
      "[CV] END ....................C=3.548850970305306, penalty=l2; total time=   1.3s\n",
      "[CV] END ....................C=3.548850970305306, penalty=l2; total time=   1.3s\n",
      "[CV] END ....................C=3.548850970305306, penalty=l2; total time=   1.3s\n",
      "[CV] END ...................C=1.8888597006477972, penalty=l2; total time=   1.0s\n",
      "[CV] END ....................C=3.548850970305306, penalty=l2; total time=   1.4s\n",
      "[CV] END ...................C=1.8888597006477972, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=1.8888597006477972, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=0.4783769837532068, penalty=l2; total time=   0.6s\n",
      "[CV] END ...................C=1.8888597006477972, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=0.4783769837532068, penalty=l2; total time=   0.6s\n",
      "[CV] END ...................C=0.4783769837532068, penalty=l2; total time=   0.7s\n",
      "[CV] END ...................C=1.8888597006477972, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=0.4783769837532068, penalty=l2; total time=   0.6s\n",
      "[CV] END ...................C=0.4783769837532068, penalty=l2; total time=   0.6s\n",
      "[CV] END .....................C=2.85297914889198, penalty=l2; total time=   1.2s\n",
      "[CV] END .....................C=2.85297914889198, penalty=l2; total time=   1.1s\n",
      "[CV] END .....................C=2.85297914889198, penalty=l2; total time=   1.2s\n",
      "[CV] END .....................C=2.85297914889198, penalty=l2; total time=   1.2s\n",
      "[CV] END .....................C=2.85297914889198, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=3.0431401944675898, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=3.0431401944675898, penalty=l2; total time=   1.2s\n",
      "[CV] END ...................C=3.0431401944675898, penalty=l2; total time=   1.2s\n",
      "[CV] END ....................C=2.245108790277985, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=3.0431401944675898, penalty=l2; total time=   1.2s\n",
      "[CV] END ....................C=2.245108790277985, penalty=l2; total time=   1.0s\n",
      "[CV] END ....................C=2.245108790277985, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=3.0431401944675898, penalty=l2; total time=   1.3s\n",
      "[CV] END ....................C=2.245108790277985, penalty=l2; total time=   1.0s\n",
      "[CV] END ....................C=2.245108790277985, penalty=l2; total time=   1.1s\n",
      "[CV] END ....................C=3.083868719818244, penalty=l2; total time=   1.2s\n",
      "[CV] END ....................C=3.083868719818244, penalty=l2; total time=   1.3s\n",
      "[CV] END ....................C=3.083868719818244, penalty=l2; total time=   1.2s\n",
      "[CV] END ....................C=3.083868719818244, penalty=l2; total time=   1.2s\n",
      "[CV] END ....................C=1.975182385457563, penalty=l2; total time=   1.0s\n",
      "[CV] END ....................C=1.975182385457563, penalty=l2; total time=   1.0s\n",
      "[CV] END ....................C=3.083868719818244, penalty=l2; total time=   1.3s\n",
      "[CV] END ....................C=1.975182385457563, penalty=l2; total time=   1.1s\n",
      "[CV] END ....................C=1.975182385457563, penalty=l2; total time=   1.0s\n",
      "[CV] END ....................C=1.975182385457563, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=2.0909313175279762, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=2.0909313175279762, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=2.0909313175279762, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=2.0909313175279762, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=1.7101640734341985, penalty=l2; total time=   1.0s\n",
      "[CV] END ..................C=0.10167650697638075, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=2.0909313175279762, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=1.7101640734341985, penalty=l2; total time=   1.0s\n",
      "[CV] END ..................C=0.10167650697638075, penalty=l2; total time=   0.3s\n",
      "[CV] END ..................C=0.10167650697638075, penalty=l2; total time=   0.3s\n",
      "[CV] END ..................C=0.10167650697638075, penalty=l2; total time=   0.3s\n",
      "[CV] END ..................C=0.10167650697638075, penalty=l2; total time=   0.3s\n",
      "[CV] END ...................C=1.7101640734341985, penalty=l2; total time=   1.0s\n",
      "[CV] END ...................C=0.4315657079732178, penalty=l2; total time=   0.5s\n",
      "[CV] END ...................C=1.7101640734341985, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................C=1.7101640734341985, penalty=l2; total time=   1.1s\n",
      "[CV] END ...................C=0.4315657079732178, penalty=l2; total time=   0.6s\n",
      "[CV] END ...................C=0.4315657079732178, penalty=l2; total time=   0.5s\n",
      "[CV] END ...................C=0.4315657079732178, penalty=l2; total time=   0.5s\n",
      "[CV] END ...................C=0.4315657079732178, penalty=l2; total time=   0.5s\n",
      "Best Hyperparameters: {'C': 3.1407038455720544, 'penalty': 'l2'}\n",
      "Best Score: 0.5015625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "param_distributions = {\n",
    "    'C': uniform(loc=0, scale=4),\n",
    "    'penalty': ['l2']\n",
    "}\n",
    "\n",
    "# Setup the randomized search with cross-validation\n",
    "random_search = RandomizedSearchCV(\n",
    "    LogisticRegression(max_iter=1000, class_weight=class_weights_dict),\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=100,\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Run the hyperparameter search\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "print(\"Best Score:\", random_search.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
